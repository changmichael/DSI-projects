{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "plt.style.use('seaborn-white')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some plotting functions to help you plot the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generic curve plotting function\n",
    "def auc_plotting_function(rate1, rate2, rate1_name, rate2_name, curve_name):\n",
    "    AUC = auc(rate1, rate2)\n",
    "    # Plot of a ROC curve for class 1 (has_cancer)\n",
    "    plt.figure(figsize=[11,9])\n",
    "    plt.plot(rate1, rate2, label=curve_name + ' (area = %0.2f)' % AUC, linewidth=4)\n",
    "    plt.plot([0, 1], [0, 1], 'k--', linewidth=4)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(rate1_name, fontsize=18)\n",
    "    plt.ylabel(rate2_name, fontsize=18)\n",
    "    plt.title(curve_name + ' for house price > 200,000', fontsize=18)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# plot receiving operator characteristic curve\n",
    "def plot_roc(y_true, y_score):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "    auc_plotting_function(fpr, tpr, 'False Positive Rate', 'True Positive Rate', 'ROC')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Sacramento housing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sac = pd.read_csv('../assets/datasets/Sacramentorealestatetransactions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a binary variable where 1 indicates a house sold for over 200,000 and 0 indicates a house sold for equal to or less than 200,000.\n",
    "\n",
    "Subset the data to just contain the number of beds, baths, the sq ft, and the over 200k indicator variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sac['over_200k'] = sac['price'].map(lambda x: 0 if x > 200000 else 1)\n",
    "sac = sac[['beds','baths','sq__ft','over_200k']]\n",
    "sac.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   beds  baths  sq__ft  over_200k\n",
      "0     2      1     836          1\n",
      "1     3      1    1167          1\n",
      "2     2      1     796          1\n",
      "3     2      1     852          1\n",
      "4     2      1     797          1\n",
      "(985, 4)\n",
      "447\n"
     ]
    }
   ],
   "source": [
    "print sac.head()\n",
    "print sac.shape\n",
    "print np.sum(sac.over_200k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split your data into training and testing sets. The predictors are the beds, baths, and sq ft. The feature is the over 200k class variable. Make the test size 33% (and optionally stratify by the over 200k class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(sac[['beds','baths','sq__ft']].values,\n",
    "                                                    sac.over_200k.values, \n",
    "                                                    test_size=0.33, stratify=sac.over_200k.values,\n",
    "                                                    random_state=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(985, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sac[['beds','baths','sq__ft']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(985,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sac.over_200k.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a logistic regression on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state=77)\n",
    "logreg.fit(X_train, Y_train)\n",
    "Y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            predicted_over_200k  predicted_under_200k\n",
      "over_200k                    69                    79\n",
      "under_200k                   51                   127\n"
     ]
    }
   ],
   "source": [
    "conmat = np.array(confusion_matrix(Y_test, Y_pred, labels=[1,0]))\n",
    "\n",
    "confusion = pd.DataFrame(conmat, index=['over_200k', 'under_200k'],\n",
    "                         columns=['predicted_over_200k','predicted_under_200k'])\n",
    "\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the accuracy, precision, and recall. What can these three metrics tell you about your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.601226993865\n",
      "0.575\n",
      "0.466216216216\n"
     ]
    }
   ],
   "source": [
    "# Accuracy tells us the percent of houses selling for over and under 200k correctly predicted\n",
    "print(accuracy_score(Y_test, Y_pred))\n",
    "\n",
    "# Precision tells us how well the classifier avoided misclassifying the over 200k houses\n",
    "print(precision_score(Y_test, Y_pred))\n",
    "\n",
    "# Recall tells us how well the classifier correctly identified houses as selling for over 200k\n",
    "print(recall_score(Y_test, Y_pred))\n",
    "\n",
    "# The difference between precision and recall can be tricky to interpret. The intuition here is\n",
    "# that precision is a measure of the QUALITY of results: of the houses labeled as over 200k,\n",
    "# how many of those were correct?\n",
    "# Recall, on the other hand, is a measure of the COMPLETENESS of results: of all the houses\n",
    "# that sold for over 200k, how many were identified by the classifier?\n",
    "# On the flip side, you can have a high precision but identify very few of the total 200k houses.\n",
    "# Likewise, you can have a high recall but also incorrectly identify many under 200k houses\n",
    "# as over 200k houses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say as a real estate agent, I prioritize minimizing false positives (predicting a house will sell for over 200k when it actually sells for under) because false positives make me lose money.\n",
    "\n",
    "Change the decision threshold to **lower the false positive rate** and then print out the new confusion matrix. What is the downside to lowering the false positive rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            predicted_over_200k  predicted_under_200k\n",
      "over_200k                    15                   133\n",
      "under_200k                   18                   160\n"
     ]
    }
   ],
   "source": [
    "Y_pp = pd.DataFrame(logreg.predict_proba(X_test), columns=['under_200k_pp','over_200k_pp'])\n",
    "\n",
    "# change the threshold to predict over 200k to 0.7 - it is harder for the classifier to assign the over 200k label\n",
    "Y_pp['over_200k_high_thresh'] = [1 if x >= 0.70 else 0 for x in Y_pp.over_200k_pp.values]\n",
    "\n",
    "conmat_high = np.array(confusion_matrix(Y_test, Y_pp.over_200k_high_thresh.values, labels=[1,0]))\n",
    "\n",
    "confusion_high = pd.DataFrame(conmat_high, index=['over_200k', 'under_200k'],\n",
    "                              columns=['predicted_over_200k','predicted_under_200k'])\n",
    "\n",
    "print(confusion_high)\n",
    "\n",
    "# The downside to lowering the false positive rate is that the false negative rate increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the ROC curve using the plotting function provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logreg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-8cbf7d80bc96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mY_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplot_roc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logreg' is not defined"
     ]
    }
   ],
   "source": [
    "Y_score = logreg.decision_function(X_test)\n",
    "plot_roc(Y_test, Y_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus: when might precision and recall be more useful than the ROC?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision and recall are more useful when the proportion of the positive class is smaller, since they are sensitive to this."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
