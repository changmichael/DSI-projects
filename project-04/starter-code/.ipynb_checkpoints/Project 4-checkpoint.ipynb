{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from IPython.core.display import HTML, Image\n",
    "from sklearn.metrics import precision_score, auc, recall_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Created several functions to help us with scraping, cleaning, and polishing the \n",
    "# data.  \n",
    "\n",
    "def get_soup_from_url(url):\n",
    "    # Give us beautiful soup for an url\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page,'lxml')\n",
    "    return soup\n",
    "\n",
    "def extract_location_from_result(result):\n",
    "    # Scrapes the location from a single result on the Indeed website\n",
    "    loca = result.find('span', class_ = 'location').text\n",
    "    location = loca.split(',')[0]\n",
    "    return str(location)\n",
    "\n",
    "def extract_company_from_result(result):\n",
    "    # Scrapes the company name from a single result on the Indeed website\n",
    "    if result.find('span', class_ = 'company') == None:\n",
    "        company = np.nan\n",
    "    else:\n",
    "        company = str(result.find('span', class_ = 'company').text.encode('ascii','ignore').strip())\n",
    "    return company\n",
    "\n",
    "def extract_jobtitle_from_result(result):\n",
    "    # Scrapes the job title from a single result on the Indeed website\n",
    "    jobtitle = result.find('a', class_ = 'jobtitle')\n",
    "    if jobtitle != None:\n",
    "        jobtitle = result.find('a',class_ = 'jobtitle').text.strip().encode('ascii','ignore')\n",
    "    else:\n",
    "        jobtitle = result.find('a').text.encode('ascii','ignore')\n",
    "    return str(jobtitle)\n",
    "\n",
    "def extract_salary_from_result(result):\n",
    "    # Scrapes the salary from a single result on the Indeed website\n",
    "    salary = result.find('nobr')\n",
    "    if salary != None:\n",
    "        salary = str(result.find('nobr').text)\n",
    "    else:\n",
    "        salary = np.nan\n",
    "    return (salary)\n",
    "\n",
    "def DollarDrop(x):\n",
    "    # gets rid of the special characters in a dollar amount on the Indeed website\n",
    "    y = x.split('$')\n",
    "    z = y[1].replace(',','')\n",
    "    return z\n",
    "\n",
    "def SalarySplitter(x):\n",
    "    # changes dollar amount from a string to a usable int (or nan if nothing there)\n",
    "    x = str(x)\n",
    "    a = x.strip().split(' ')\n",
    "    tenor = a[-1]\n",
    "    if tenor == 'year':\n",
    "        if a[1] == '-':\n",
    "            salary = (int(DollarDrop(a[0])) + int(DollarDrop(a[2])))/2\n",
    "        else:\n",
    "            salary = int(DollarDrop(a[0]))\n",
    "    else:\n",
    "        salary = np.nan\n",
    "    return salary\n",
    "\n",
    "def words_in_string(wordList, x):\n",
    "    # matches the words for the word filter in lowercase letters\n",
    "    for word in x.split():\n",
    "        if word.lower() in wordList:\n",
    "            return word.lower()\n",
    "    return 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  Setting up a loop to take in several cities with max results to scrape for data\n",
    "url_template = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l={city}&start={start}\"\n",
    "max_results_per_city = 300\n",
    "\n",
    "results = []\n",
    "\n",
    "for city in set(['New+York', 'Chicago', 'Los+Angeles', 'Seattle', 'San+Francisco', 'Baltimore', 'Atlanta', 'Boston', \n",
    "                 'Dallas', 'Raleigh', 'Philadelphia']):\n",
    "    url_prep = (url_template.replace('{city}',city))\n",
    "    for start in range(0, max_results_per_city, 10):\n",
    "        url = url_prep.replace('{start}',str(start))\n",
    "        # Grabbing the results from the request (as above) with multiple cities then \n",
    "        # appending the full set of data to the results list\n",
    "        soup = get_soup_from_url(url)\n",
    "        for element in soup.findAll('div',class_ = 'result'):\n",
    "            preResult=[]\n",
    "            preResult.append(extract_jobtitle_from_result(element))\n",
    "            preResult.append(extract_company_from_result(element))\n",
    "            preResult.append(extract_location_from_result(element))\n",
    "            cityTag = city.replace('+',' ')\n",
    "            preResult.append(cityTag)\n",
    "            preResult.append(extract_salary_from_result(element))\n",
    "            results.append(preResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Making a dataframe out of results complete with new column names, also making the numbers in salary\n",
    "# ints instead of strings.  Finally dropping all na rows as we're interested in the rows with \n",
    "# salary information.\n",
    "df = pd.DataFrame(results, columns  = ['JobTitle', 'CompanyName', 'City', 'CityGrouping', 'Salary'])\n",
    "df['Salary'] = df['Salary'].apply(lambda x: SalarySplitter(x))\n",
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  Saving the dataframe to a csv file.  Important as it takes 2-3 minutes to do the scrape...\n",
    "df.to_csv('SalaryInfo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reading in the csv... using this as a \"checkpoint\" when i have to redo calcs\n",
    "workdf = pd.read_csv('SalaryInfo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Getting the median of the salary to set up the \"HighSalary\" column, also setting up and\n",
    "# then using the \"expensive\" words bucket to see if they have a bearing in job title\n",
    "SalaryMedian = workdf['Salary'].median()\n",
    "workdf['HighSalary']=[x>SalaryMedian for x in workdf['Salary']]\n",
    "ExpensiveWords = ['senior', 'sr.', 'sr', 'manager']\n",
    "workdf['WordTest'] = workdf['JobTitle'].apply(lambda x: words_in_string(ExpensiveWords,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.584500\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.157</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>    <td>HighSalary</td>          <td>AIC:</td>         <td>262.8138</td> \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2016-07-07 08:42</td>       <td>BIC:</td>         <td>299.4205</td> \n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>         <td>206</td>        <td>Log-Likelihood:</td>    <td>-120.41</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>             <td>10</td>            <td>LL-Null:</td>        <td>-142.75</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>           <td>195</td>         <td>LLR p-value:</td>    <td>2.4784e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>         <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Baltimore</th>     <td>-0.1490</td>  <td>0.6662</td>  <td>-0.2237</td> <td>0.8230</td> <td>-1.4548</td> <td>1.1567</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Boston</th>        <td>1.4816</td>   <td>0.6917</td>  <td>2.1421</td>  <td>0.0322</td> <td>0.1260</td>  <td>2.8373</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Chicago</th>       <td>2.0794</td>   <td>0.6614</td>  <td>3.1438</td>  <td>0.0017</td> <td>0.7830</td>  <td>3.3758</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dallas</th>        <td>0.4700</td>   <td>0.7984</td>  <td>0.5887</td>  <td>0.5561</td> <td>-1.0949</td> <td>2.0349</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Los Angeles</th>   <td>-0.3409</td>  <td>0.9347</td>  <td>-0.3648</td> <td>0.7153</td> <td>-2.1728</td> <td>1.4910</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>New York</th>      <td>1.4508</td>   <td>0.6390</td>  <td>2.2704</td>  <td>0.0232</td> <td>0.1984</td>  <td>2.7033</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Philadelphia</th>  <td>1.3455</td>   <td>0.7932</td>  <td>1.6963</td>  <td>0.0898</td> <td>-0.2092</td> <td>2.9001</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Raleigh</th>       <td>0.8755</td>   <td>0.7444</td>  <td>1.1760</td>  <td>0.2396</td> <td>-0.5836</td> <td>2.3345</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>San Francisco</th> <td>2.4849</td>   <td>0.7610</td>  <td>3.2652</td>  <td>0.0011</td> <td>0.9933</td>  <td>3.9765</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seattle</th>       <td>3.3604</td>   <td>1.1720</td>  <td>2.8672</td>  <td>0.0041</td> <td>1.0633</td>  <td>5.6575</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>     <td>-1.1632</td>  <td>0.5123</td>  <td>-2.2702</td> <td>0.0232</td> <td>-2.1673</td> <td>-0.1590</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "=================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.157     \n",
       "Dependent Variable: HighSalary       AIC:              262.8138  \n",
       "Date:               2016-07-07 08:42 BIC:              299.4205  \n",
       "No. Observations:   206              Log-Likelihood:   -120.41   \n",
       "Df Model:           10               LL-Null:          -142.75   \n",
       "Df Residuals:       195              LLR p-value:      2.4784e-06\n",
       "Converged:          1.0000           Scale:            1.0000    \n",
       "No. Iterations:     6.0000                                       \n",
       "-----------------------------------------------------------------\n",
       "                   Coef.  Std.Err.    z    P>|z|   [0.025  0.975]\n",
       "-----------------------------------------------------------------\n",
       "Baltimore         -0.1490   0.6662 -0.2237 0.8230 -1.4548  1.1567\n",
       "Boston             1.4816   0.6917  2.1421 0.0322  0.1260  2.8373\n",
       "Chicago            2.0794   0.6614  3.1438 0.0017  0.7830  3.3758\n",
       "Dallas             0.4700   0.7984  0.5887 0.5561 -1.0949  2.0349\n",
       "Los Angeles       -0.3409   0.9347 -0.3648 0.7153 -2.1728  1.4910\n",
       "New York           1.4508   0.6390  2.2704 0.0232  0.1984  2.7033\n",
       "Philadelphia       1.3455   0.7932  1.6963 0.0898 -0.2092  2.9001\n",
       "Raleigh            0.8755   0.7444  1.1760 0.2396 -0.5836  2.3345\n",
       "San Francisco      2.4849   0.7610  3.2652 0.0011  0.9933  3.9765\n",
       "Seattle            3.3604   1.1720  2.8672 0.0041  1.0633  5.6575\n",
       "intercept         -1.1632   0.5123 -2.2702 0.0232 -2.1673 -0.1590\n",
       "=================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running logistic regression in statsmodel on the city groupings - please note\n",
    "# we're running this on the cities we used for filtering rather than the actual\n",
    "# city as there are many small cities that are lumped into the larger cities' filters\n",
    "dummy_ranks = pd.get_dummies(workdf['CityGrouping'])\n",
    "cols_to_keep = ['HighSalary']\n",
    "data = workdf[cols_to_keep].join(dummy_ranks[list(dummy_ranks.columns[1:])])\n",
    "data['intercept'] = 1.0\n",
    "train_cols = data.columns[1:]\n",
    "logit = sm.Logit(data['HighSalary'], data[train_cols])\n",
    "result = logit.fit()\n",
    "result.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.654152\n",
      "         Iterations: 35\n",
      "         Function evaluations: 36\n",
      "         Gradient evaluations: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michael/anaconda/lib/python2.7/site-packages/statsmodels/base/model.py:466: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>   <td>0.056</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>    <td>HighSalary</td>          <td>AIC:</td>        <td>279.5105</td> \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2016-07-07 08:42</td>       <td>BIC:</td>        <td>296.1499</td> \n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>         <td>206</td>        <td>Log-Likelihood:</td>   <td>-134.76</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>4</td>            <td>LL-Null:</td>       <td>-142.75</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>           <td>201</td>         <td>LLR p-value:</td>    <td>0.0030347</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>0.0000</td>           <td>Scale:</td>        <td>1.0000</td>  \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th>   <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>none</th>      <td>-0.2201</td>  <td>0.9087</td>  <td>-0.2422</td> <td>0.8086</td>   <td>-2.0010</td>   <td>1.5609</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>senior</th>    <td>1.3096</td>   <td>1.0060</td>  <td>1.3017</td>  <td>0.1930</td>   <td>-0.6622</td>   <td>3.2814</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sr</th>        <td>14.1256</td> <td>821.3902</td> <td>0.0172</td>  <td>0.9863</td> <td>-1595.7696</td> <td>1624.0208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sr.</th>       <td>-0.7626</td>  <td>1.0752</td>  <td>-0.7092</td> <td>0.4782</td>   <td>-2.8699</td>   <td>1.3447</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>-0.0105</td>  <td>0.8944</td>  <td>-0.0117</td> <td>0.9907</td>   <td>-1.7635</td>   <td>1.7426</td>  \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.056    \n",
       "Dependent Variable: HighSalary       AIC:              279.5105 \n",
       "Date:               2016-07-07 08:42 BIC:              296.1499 \n",
       "No. Observations:   206              Log-Likelihood:   -134.76  \n",
       "Df Model:           4                LL-Null:          -142.75  \n",
       "Df Residuals:       201              LLR p-value:      0.0030347\n",
       "Converged:          0.0000           Scale:            1.0000   \n",
       "----------------------------------------------------------------\n",
       "             Coef.  Std.Err.    z    P>|z|    [0.025     0.975] \n",
       "----------------------------------------------------------------\n",
       "none        -0.2201   0.9087 -0.2422 0.8086    -2.0010    1.5609\n",
       "senior       1.3096   1.0060  1.3017 0.1930    -0.6622    3.2814\n",
       "sr          14.1256 821.3902  0.0172 0.9863 -1595.7696 1624.0208\n",
       "sr.         -0.7626   1.0752 -0.7092 0.4782    -2.8699    1.3447\n",
       "intercept   -0.0105   0.8944 -0.0117 0.9907    -1.7635    1.7426\n",
       "================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This logistic regression is done on key words in teh job title to see if there is \n",
    "# any effect. As we see from the results... there is not really any effect.\n",
    "dummyWord_ranks = pd.get_dummies(workdf['WordTest'])\n",
    "cols_to_keep = ['HighSalary']\n",
    "dataWord = workdf[cols_to_keep].join(dummyWord_ranks[list(dummyWord_ranks.columns[1:])])\n",
    "dataWord['intercept'] = 1.0\n",
    "train_colsWord = dataWord.columns[1:]\n",
    "logitWord = sm.Logit(dataWord['HighSalary'], dataWord[train_colsWord])\n",
    "resultWord = logitWord.fit(method='bfgs')\n",
    "resultWord.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.563781\n",
      "         Iterations: 35\n",
      "         Function evaluations: 37\n",
      "         Gradient evaluations: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michael/anaconda/lib/python2.7/site-packages/statsmodels/base/model.py:466: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.186</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>    <td>HighSalary</td>          <td>AIC:</td>         <td>262.2778</td> \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2016-07-07 08:42</td>       <td>BIC:</td>         <td>312.1960</td> \n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>         <td>206</td>        <td>Log-Likelihood:</td>    <td>-116.14</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>             <td>14</td>            <td>LL-Null:</td>        <td>-142.75</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>           <td>191</td>         <td>LLR p-value:</td>    <td>1.7445e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>0.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>         <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>none</th>          <td>-0.2500</td>  <td>0.9649</td>  <td>-0.2590</td> <td>0.7956</td> <td>-2.1412</td> <td>1.6412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>senior</th>        <td>1.0065</td>   <td>1.0767</td>  <td>0.9348</td>  <td>0.3499</td> <td>-1.1038</td> <td>3.1168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sr</th>            <td>2.6259</td>   <td>2.4042</td>  <td>1.0922</td>  <td>0.2747</td> <td>-2.0862</td> <td>7.3380</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sr.</th>           <td>-0.6093</td>  <td>1.1856</td>  <td>-0.5139</td> <td>0.6073</td> <td>-2.9331</td> <td>1.7145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Baltimore</th>     <td>-0.1517</td>  <td>0.6839</td>  <td>-0.2218</td> <td>0.8244</td> <td>-1.4921</td> <td>1.1887</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Boston</th>        <td>1.1626</td>   <td>0.7184</td>  <td>1.6183</td>  <td>0.1056</td> <td>-0.2455</td> <td>2.5708</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Chicago</th>       <td>1.7411</td>   <td>0.6688</td>  <td>2.6035</td>  <td>0.0092</td> <td>0.4304</td>  <td>3.0519</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dallas</th>        <td>0.4199</td>   <td>0.8250</td>  <td>0.5089</td>  <td>0.6108</td> <td>-1.1971</td> <td>2.0368</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Los Angeles</th>   <td>-0.6156</td>  <td>0.9861</td>  <td>-0.6243</td> <td>0.5324</td> <td>-2.5484</td> <td>1.3171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>New York</th>      <td>1.2784</td>   <td>0.6552</td>  <td>1.9513</td>  <td>0.0510</td> <td>-0.0057</td> <td>2.5625</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Philadelphia</th>  <td>1.1155</td>   <td>0.8170</td>  <td>1.3653</td>  <td>0.1722</td> <td>-0.4858</td> <td>2.7168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Raleigh</th>       <td>0.6535</td>   <td>0.7766</td>  <td>0.8415</td>  <td>0.4001</td> <td>-0.8686</td> <td>2.1756</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>San Francisco</th> <td>2.1857</td>   <td>0.7830</td>  <td>2.7914</td>  <td>0.0052</td> <td>0.6510</td>  <td>3.7203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seattle</th>       <td>3.5346</td>   <td>1.3015</td>  <td>2.7157</td>  <td>0.0066</td> <td>0.9836</td>  <td>6.0855</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>     <td>-0.9280</td>  <td>1.0509</td>  <td>-0.8831</td> <td>0.3772</td> <td>-2.9877</td> <td>1.1316</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "=================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.186     \n",
       "Dependent Variable: HighSalary       AIC:              262.2778  \n",
       "Date:               2016-07-07 08:42 BIC:              312.1960  \n",
       "No. Observations:   206              Log-Likelihood:   -116.14   \n",
       "Df Model:           14               LL-Null:          -142.75   \n",
       "Df Residuals:       191              LLR p-value:      1.7445e-06\n",
       "Converged:          0.0000           Scale:            1.0000    \n",
       "------------------------------------------------------------------\n",
       "                Coef.   Std.Err.     z     P>|z|    [0.025  0.975]\n",
       "------------------------------------------------------------------\n",
       "none           -0.2500    0.9649  -0.2590  0.7956  -2.1412  1.6412\n",
       "senior          1.0065    1.0767   0.9348  0.3499  -1.1038  3.1168\n",
       "sr              2.6259    2.4042   1.0922  0.2747  -2.0862  7.3380\n",
       "sr.            -0.6093    1.1856  -0.5139  0.6073  -2.9331  1.7145\n",
       "Baltimore      -0.1517    0.6839  -0.2218  0.8244  -1.4921  1.1887\n",
       "Boston          1.1626    0.7184   1.6183  0.1056  -0.2455  2.5708\n",
       "Chicago         1.7411    0.6688   2.6035  0.0092   0.4304  3.0519\n",
       "Dallas          0.4199    0.8250   0.5089  0.6108  -1.1971  2.0368\n",
       "Los Angeles    -0.6156    0.9861  -0.6243  0.5324  -2.5484  1.3171\n",
       "New York        1.2784    0.6552   1.9513  0.0510  -0.0057  2.5625\n",
       "Philadelphia    1.1155    0.8170   1.3653  0.1722  -0.4858  2.7168\n",
       "Raleigh         0.6535    0.7766   0.8415  0.4001  -0.8686  2.1756\n",
       "San Francisco   2.1857    0.7830   2.7914  0.0052   0.6510  3.7203\n",
       "Seattle         3.5346    1.3015   2.7157  0.0066   0.9836  6.0855\n",
       "intercept      -0.9280    1.0509  -0.8831  0.3772  -2.9877  1.1316\n",
       "=================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining both the cities and \"expensive\" words to see how it looks.  it's just okay... \n",
    "dataFull = workdf[cols_to_keep].join(dummyWord_ranks[list(dummyWord_ranks.columns[1:])]).join(dummy_ranks[list(dummy_ranks.columns[1:])])\n",
    "dataFull['intercept'] = 1.0\n",
    "train_colsFull = dataFull.columns[1:]\n",
    "logitFull = sm.Logit(dataFull['HighSalary'], dataFull[train_colsFull])\n",
    "resultFull = logitFull.fit(method='bfgs')\n",
    "resultFull.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redoing the logistic regression models in scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setting the target and data variables\n",
    "y = dataFull['HighSalary']\n",
    "X= dataFull[train_colsFull]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Running the test-train-split, fitting and predicting \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=99)\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "lr_model = lr.fit(X_train, y_train)\n",
    "lr_ypred = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       False  True \n",
       "False     24     11\n",
       "True      18     15"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix generation\n",
    "lr_cm = confusion_matrix(y_test, lr_ypred, labels=lr.classes_)\n",
    "lr_cm = pd.DataFrame(lr_cm, columns=lr.classes_, index=lr.classes_)\n",
    "lr_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.57      0.69      0.62        35\n",
      "       True       0.58      0.45      0.51        33\n",
      "\n",
      "avg / total       0.57      0.57      0.57        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report generation\n",
    "print(classification_report(y_test, lr_ypred, labels=lr.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.475987496448\n",
      "0.573529411765\n"
     ]
    }
   ],
   "source": [
    "# Getting the cross val score and also the accuracy score\n",
    "print(cross_val_score(lr, X, y, cv=3).mean())\n",
    "print(accuracy_score(y_test, lr_ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Looking at L1 and L2 regularization\n",
    "lr1 = LogisticRegression(penalty='l1')\n",
    "lr2 = LogisticRegression(penalty='l2')\n",
    "\n",
    "lr1_model = lr1.fit(X_train, y_train)\n",
    "lr2_model = lr2.fit(X_train, y_train)\n",
    "\n",
    "y1_pred = lr1.predict(X_test)\n",
    "y2_pred = lr2.predict(X_test)\n",
    "\n",
    "cm1 = confusion_matrix(y_test, y1_pred, labels=lr1.classes_)\n",
    "cm1 = pd.DataFrame(cm1, columns=lr1.classes_, index=lr1.classes_)\n",
    "\n",
    "cm2 = confusion_matrix(y_test, y2_pred, labels=lr2.classes_)\n",
    "cm2 = pd.DataFrame(cm2, columns=lr2.classes_, index=lr2.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       False  True \n",
       "False     26      9\n",
       "True      20     13"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       False  True \n",
       "False     24     11\n",
       "True      18     15"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.57      0.74      0.64        35\n",
      "       True       0.59      0.39      0.47        33\n",
      "\n",
      "avg / total       0.58      0.57      0.56        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y1_pred, labels=lr2.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.57      0.69      0.62        35\n",
      "       True       0.58      0.45      0.51        33\n",
      "\n",
      "avg / total       0.57      0.57      0.57        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y2_pred, labels=lr1.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.7825594])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking a look at cross val logistic regression\n",
    "lrcv = LogisticRegressionCV(penalty='l1', solver='liblinear')\n",
    "lrcv_model = lrcv.fit(X_train, y_train)\n",
    "lrcv_ypred = lrcv_model.predict(X_test)\n",
    "lrcv_model.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       False  True \n",
       "False     24     11\n",
       "True      18     15"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrcv_cm = confusion_matrix(y_test, lrcv_ypred, labels=lrcv.classes_)\n",
    "lrcv_cm = pd.DataFrame(lrcv_cm, columns=lrcv.classes_, index=lrcv.classes_)\n",
    "lrcv_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.57      0.69      0.62        35\n",
      "       True       0.58      0.45      0.51        33\n",
      "\n",
      "avg / total       0.57      0.57      0.57        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, lrcv_ypred, labels=lrcv.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=15, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [0.0001, 0.001, 0.01, 0.1, 0.15, 0.25, 0.275, 0.33, 0.5, 0.66, 0.75, 1.0, 2.5, 5.0, 10.0, 100.0, 1000.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using grid search to find the best C Values\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "C_vals = [0.0001, 0.001, 0.01, 0.1, .15, .25, .275, .33, 0.5, .66, 0.75, 1.0, 2.5, 5.0, 10.0, 100.0, 1000.0]\n",
    "penalties = ['l1','l2']\n",
    "\n",
    "gs = GridSearchCV(logreg, {'penalty': penalties, 'C': C_vals}, verbose=False, cv=15)\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.001, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=gs.best_params_['C'], penalty=gs.best_params_['penalty'])\n",
    "cv_model = logreg.fit(X_train, y_train)\n",
    "cv_pred = cv_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm3 = confusion_matrix(y_test, cv_pred, labels=logreg.classes_)\n",
    "cm3 = pd.DataFrame(cm3, columns=logreg.classes_, index=logreg.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       False  True \n",
       "False     32      3\n",
       "True      26      7"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.55      0.91      0.69        35\n",
      "       True       0.70      0.21      0.33        33\n",
      "\n",
      "avg / total       0.62      0.57      0.51        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, cv_pred, labels=logreg.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Features and Classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying a new set of classifications to see if they have any bearing on salaries.  In this case, we're going to see if the company itself has any significant bearing on the salary.  We'll be using a basket of the \"recruiting\" names in tech to see if they pay out better than the companies looking for candidates directly, i.e. do companies like Workbridge Associates, Staffing companies, etc advertise a premium to others in data science?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reading in the csv to start \"afresh\"... using this as a \"checkpoint\" when i have to redo calcs\n",
    "newWorkdf = pd.read_csv('SalaryInfo.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Getting the median of the salary to set up the \"HighSalary\" column, also setting up and\n",
    "# then using the \"expensive\" words bucket to see if they have a bearing in job title\n",
    "SalaryMedian = newWorkdf['Salary'].median()\n",
    "newWorkdf['HighSalary']=[x>SalaryMedian for x in newWorkdf['Salary']]\n",
    "CompanyNames = ['associates','employment','staffing','search','hanley','careers', 'jobspring']\n",
    "newWorkdf['CompanyTest'] = newWorkdf['CompanyName'].apply(lambda x: words_in_string(CompanyNames,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hanley'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_string(CompanyNames,'Smith Hanley')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>JobTitle</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>City</th>\n",
       "      <th>CityGrouping</th>\n",
       "      <th>Salary</th>\n",
       "      <th>HighSalary</th>\n",
       "      <th>CompanyTest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>Mid-Level Data Scientist</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>associates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>associates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>Sr. Statistician</td>\n",
       "      <td>Etech Hi Inc.</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>associates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>Statistician</td>\n",
       "      <td>Etech Hi Inc.</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>71000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                  JobTitle            CompanyName     City  \\\n",
       "0           7  Mid-Level Data Scientist  Workbridge Associates  Chicago   \n",
       "1          12            Data Scientist  Workbridge Associates  Chicago   \n",
       "2          22          Sr. Statistician          Etech Hi Inc.  Chicago   \n",
       "3          49     Senior Data Scientist  Workbridge Associates  Chicago   \n",
       "4          51              Statistician          Etech Hi Inc.  Chicago   \n",
       "\n",
       "  CityGrouping    Salary HighSalary CompanyTest  \n",
       "0      Chicago  105000.0      False  associates  \n",
       "1      Chicago   95000.0      False  associates  \n",
       "2      Chicago   85000.0      False        none  \n",
       "3      Chicago  140000.0       True  associates  \n",
       "4      Chicago   71000.0      False        none  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newWorkdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "none          156\n",
       "associates     22\n",
       "hanley          8\n",
       "search          6\n",
       "jobspring       6\n",
       "staffing        4\n",
       "employment      3\n",
       "careers         1\n",
       "Name: CompanyTest, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newWorkdf['CompanyTest'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.618203\n",
      "         Iterations: 35\n",
      "         Function evaluations: 36\n",
      "         Gradient evaluations: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michael/anaconda/lib/python2.7/site-packages/statsmodels/base/model.py:466: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.108</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>    <td>HighSalary</td>          <td>AIC:</td>         <td>270.6995</td> \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2016-07-07 09:49</td>       <td>BIC:</td>         <td>297.3225</td> \n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>         <td>206</td>        <td>Log-Likelihood:</td>    <td>-127.35</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>7</td>            <td>LL-Null:</td>        <td>-142.75</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>           <td>198</td>         <td>LLR p-value:</td>    <td>6.7696e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>0.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>       <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th>  <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>careers</th>    <td>-3.4243</td>  <td>2.3160</td>  <td>-1.4785</td> <td>0.1393</td>  <td>-7.9635</td> <td>1.1149</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>employment</th> <td>3.0726</td>   <td>10.1820</td> <td>0.3018</td>  <td>0.7628</td> <td>-16.8838</td> <td>23.0290</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hanley</th>     <td>-3.2360</td>  <td>1.1329</td>  <td>-2.8564</td> <td>0.0043</td>  <td>-5.4564</td> <td>-1.0156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>jobspring</th>  <td>-2.6121</td>  <td>1.1861</td>  <td>-2.2023</td> <td>0.0276</td>  <td>-4.9367</td> <td>-0.2875</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>none</th>       <td>-2.9057</td>  <td>0.8751</td>  <td>-3.3203</td> <td>0.0009</td>  <td>-4.6209</td> <td>-1.1905</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>search</th>     <td>-1.9492</td>  <td>1.2217</td>  <td>-1.5955</td> <td>0.1106</td>  <td>-4.3438</td> <td>0.4453</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>staffing</th>   <td>-7.4409</td>  <td>5.5888</td>  <td>-1.3314</td> <td>0.1831</td> <td>-18.3947</td> <td>3.5130</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>  <td>2.6536</td>   <td>0.8601</td>  <td>3.0852</td>  <td>0.0020</td>  <td>0.9678</td>  <td>4.3394</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "=================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.108     \n",
       "Dependent Variable: HighSalary       AIC:              270.6995  \n",
       "Date:               2016-07-07 09:49 BIC:              297.3225  \n",
       "No. Observations:   206              Log-Likelihood:   -127.35   \n",
       "Df Model:           7                LL-Null:          -142.75   \n",
       "Df Residuals:       198              LLR p-value:      6.7696e-05\n",
       "Converged:          0.0000           Scale:            1.0000    \n",
       "------------------------------------------------------------------\n",
       "              Coef.   Std.Err.     z     P>|z|    [0.025    0.975]\n",
       "------------------------------------------------------------------\n",
       "careers      -3.4243    2.3160  -1.4785  0.1393   -7.9635   1.1149\n",
       "employment    3.0726   10.1820   0.3018  0.7628  -16.8838  23.0290\n",
       "hanley       -3.2360    1.1329  -2.8564  0.0043   -5.4564  -1.0156\n",
       "jobspring    -2.6121    1.1861  -2.2023  0.0276   -4.9367  -0.2875\n",
       "none         -2.9057    0.8751  -3.3203  0.0009   -4.6209  -1.1905\n",
       "search       -1.9492    1.2217  -1.5955  0.1106   -4.3438   0.4453\n",
       "staffing     -7.4409    5.5888  -1.3314  0.1831  -18.3947   3.5130\n",
       "intercept     2.6536    0.8601   3.0852  0.0020    0.9678   4.3394\n",
       "=================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This logistic regression is done on key words in the company name to see if there is \n",
    "# any effect.\n",
    "dummyCompany_ranks = pd.get_dummies(newWorkdf['CompanyTest'])\n",
    "cols_to_keep = ['HighSalary']\n",
    "dataCompany = newWorkdf[cols_to_keep].join(dummyCompany_ranks[list(dummyCompany_ranks.columns[1:])])\n",
    "dataCompany['intercept'] = 1.0\n",
    "train_colsCompany = dataCompany.columns[1:]\n",
    "logitCompany = sm.Logit(dataCompany['HighSalary'], dataCompany[train_colsCompany])\n",
    "resultCompany = logitCompany.fit(method='bfgs')\n",
    "resultCompany.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
