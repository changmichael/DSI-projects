{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from IPython.core.display import HTML, Image\n",
    "from sklearn.metrics import precision_score, auc, recall_score, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Created several functions to help us with scraping, cleaning, and polishing the \n",
    "# data.  \n",
    "\n",
    "def get_soup_from_url(url):\n",
    "    # Give us beautiful soup for an url\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page,'lxml')\n",
    "    return soup\n",
    "\n",
    "def extract_location_from_result(result):\n",
    "    # Scrapes the location from a single result on the Indeed website\n",
    "    loca = result.find('span', class_ = 'location').text\n",
    "    location = loca.split(',')[0]\n",
    "    return str(location)\n",
    "\n",
    "def extract_company_from_result(result):\n",
    "    # Scrapes the company name from a single result on the Indeed website\n",
    "    if result.find('span', class_ = 'company') == None:\n",
    "        company = np.nan\n",
    "    else:\n",
    "        company = str(result.find('span', class_ = 'company').text.encode('ascii','ignore').strip())\n",
    "    return company\n",
    "\n",
    "def extract_jobtitle_from_result(result):\n",
    "    # Scrapes the job title from a single result on the Indeed website\n",
    "    jobtitle = result.find('a', class_ = 'jobtitle')\n",
    "    if jobtitle != None:\n",
    "        jobtitle = result.find('a',class_ = 'jobtitle').text.strip().encode('ascii','ignore')\n",
    "    else:\n",
    "        jobtitle = result.find('a').text.encode('ascii','ignore')\n",
    "    return str(jobtitle)\n",
    "\n",
    "def extract_salary_from_result(result):\n",
    "    # Scrapes the salary from a single result on the Indeed website\n",
    "    salary = result.find('nobr')\n",
    "    if salary != None:\n",
    "        salary = str(result.find('nobr').text)\n",
    "    else:\n",
    "        salary = np.nan\n",
    "    return (salary)\n",
    "\n",
    "def DollarDrop(x):\n",
    "    # gets rid of the special characters in a dollar amount on the Indeed website\n",
    "    y = x.split('$')\n",
    "    z = y[1].replace(',','')\n",
    "    return z\n",
    "\n",
    "def SalarySplitter(x):\n",
    "    # changes dollar amount from a string to a usable int (or nan if nothing there)\n",
    "    x = str(x)\n",
    "    a = x.strip().split(' ')\n",
    "    tenor = a[-1]\n",
    "    if tenor == 'year':\n",
    "        if a[1] == '-':\n",
    "            salary = (int(DollarDrop(a[0])) + int(DollarDrop(a[2])))/2\n",
    "        else:\n",
    "            salary = int(DollarDrop(a[0]))\n",
    "    else:\n",
    "        salary = np.nan\n",
    "    return salary\n",
    "\n",
    "def words_in_string(wordList, x):\n",
    "    # matches the words for the word filter in lowercase letters\n",
    "    for word in x.split():\n",
    "        if word.lower() in wordList:\n",
    "            return word.lower()\n",
    "    return 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  Setting up a loop to take in several cities with max results to scrape for data\n",
    "url_template = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l={city}&start={start}\"\n",
    "max_results_per_city = 300\n",
    "\n",
    "results = []\n",
    "\n",
    "for city in set(['New+York', 'Chicago', 'Los+Angeles', 'Seattle', 'San+Francisco', 'Baltimore', 'Atlanta', 'Boston', \n",
    "                 'Dallas', 'Raleigh', 'Philadelphia']):\n",
    "    url_prep = (url_template.replace('{city}',city))\n",
    "    for start in range(0, max_results_per_city, 10):\n",
    "        url = url_prep.replace('{start}',str(start))\n",
    "        # Grabbing the results from the request (as above) with multiple cities then \n",
    "        # appending the full set of data to the results list\n",
    "        soup = get_soup_from_url(url)\n",
    "        for element in soup.findAll('div',class_ = 'result'):\n",
    "            preResult=[]\n",
    "            preResult.append(extract_jobtitle_from_result(element))\n",
    "            preResult.append(extract_company_from_result(element))\n",
    "            preResult.append(extract_location_from_result(element))\n",
    "            cityTag = city.replace('+',' ')\n",
    "            preResult.append(cityTag)\n",
    "            preResult.append(extract_salary_from_result(element))\n",
    "            results.append(preResult)\n",
    "            \n",
    "# Making a dataframe out of results complete with new column names, also making the numbers in salary\n",
    "# ints instead of strings.  Finally dropping all na rows as we're interested in the rows with \n",
    "# salary information.\n",
    "df = pd.DataFrame(results, columns  = ['JobTitle', 'CompanyName', 'City', 'CityGrouping', 'Salary'])\n",
    "df['Salary'] = df['Salary'].apply(lambda x: SalarySplitter(x))\n",
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  Saving the dataframe to a csv file.  Important as it takes 2-3 minutes to do the scrape...\n",
    "df.to_csv('SalaryInfo.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reading in the csv... using this as a \"checkpoint\" when i have to redo calcs\n",
    "workdf = pd.read_csv('SalaryInfo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Getting the median of the salary to set up the \"HighSalary\" column, also setting up and\n",
    "# then using the \"expensive\" words bucket to see if they have a bearing in job title\n",
    "SalaryMedian = workdf['Salary'].median()\n",
    "workdf['HighSalary']=[x>SalaryMedian for x in workdf['Salary']]\n",
    "ExpensiveWords = ['senior', 'sr.', 'sr', 'manager']\n",
    "workdf['WordTest'] = workdf['JobTitle'].apply(lambda x: words_in_string(ExpensiveWords,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.584500\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.157</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>    <td>HighSalary</td>          <td>AIC:</td>         <td>262.8138</td> \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2016-07-07 17:10</td>       <td>BIC:</td>         <td>299.4205</td> \n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>         <td>206</td>        <td>Log-Likelihood:</td>    <td>-120.41</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>             <td>10</td>            <td>LL-Null:</td>        <td>-142.75</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>           <td>195</td>         <td>LLR p-value:</td>    <td>2.4784e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>         <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Baltimore</th>     <td>-0.1490</td>  <td>0.6662</td>  <td>-0.2237</td> <td>0.8230</td> <td>-1.4548</td> <td>1.1567</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Boston</th>        <td>1.4816</td>   <td>0.6917</td>  <td>2.1421</td>  <td>0.0322</td> <td>0.1260</td>  <td>2.8373</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Chicago</th>       <td>2.0794</td>   <td>0.6614</td>  <td>3.1438</td>  <td>0.0017</td> <td>0.7830</td>  <td>3.3758</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dallas</th>        <td>0.4700</td>   <td>0.7984</td>  <td>0.5887</td>  <td>0.5561</td> <td>-1.0949</td> <td>2.0349</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Los Angeles</th>   <td>-0.3409</td>  <td>0.9347</td>  <td>-0.3648</td> <td>0.7153</td> <td>-2.1728</td> <td>1.4910</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>New York</th>      <td>1.4508</td>   <td>0.6390</td>  <td>2.2704</td>  <td>0.0232</td> <td>0.1984</td>  <td>2.7033</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Philadelphia</th>  <td>1.3455</td>   <td>0.7932</td>  <td>1.6963</td>  <td>0.0898</td> <td>-0.2092</td> <td>2.9001</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Raleigh</th>       <td>0.8755</td>   <td>0.7444</td>  <td>1.1760</td>  <td>0.2396</td> <td>-0.5836</td> <td>2.3345</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>San Francisco</th> <td>2.4849</td>   <td>0.7610</td>  <td>3.2652</td>  <td>0.0011</td> <td>0.9933</td>  <td>3.9765</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seattle</th>       <td>3.3604</td>   <td>1.1720</td>  <td>2.8672</td>  <td>0.0041</td> <td>1.0633</td>  <td>5.6575</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>     <td>-1.1632</td>  <td>0.5123</td>  <td>-2.2702</td> <td>0.0232</td> <td>-2.1673</td> <td>-0.1590</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "=================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.157     \n",
       "Dependent Variable: HighSalary       AIC:              262.8138  \n",
       "Date:               2016-07-07 17:10 BIC:              299.4205  \n",
       "No. Observations:   206              Log-Likelihood:   -120.41   \n",
       "Df Model:           10               LL-Null:          -142.75   \n",
       "Df Residuals:       195              LLR p-value:      2.4784e-06\n",
       "Converged:          1.0000           Scale:            1.0000    \n",
       "No. Iterations:     6.0000                                       \n",
       "-----------------------------------------------------------------\n",
       "                   Coef.  Std.Err.    z    P>|z|   [0.025  0.975]\n",
       "-----------------------------------------------------------------\n",
       "Baltimore         -0.1490   0.6662 -0.2237 0.8230 -1.4548  1.1567\n",
       "Boston             1.4816   0.6917  2.1421 0.0322  0.1260  2.8373\n",
       "Chicago            2.0794   0.6614  3.1438 0.0017  0.7830  3.3758\n",
       "Dallas             0.4700   0.7984  0.5887 0.5561 -1.0949  2.0349\n",
       "Los Angeles       -0.3409   0.9347 -0.3648 0.7153 -2.1728  1.4910\n",
       "New York           1.4508   0.6390  2.2704 0.0232  0.1984  2.7033\n",
       "Philadelphia       1.3455   0.7932  1.6963 0.0898 -0.2092  2.9001\n",
       "Raleigh            0.8755   0.7444  1.1760 0.2396 -0.5836  2.3345\n",
       "San Francisco      2.4849   0.7610  3.2652 0.0011  0.9933  3.9765\n",
       "Seattle            3.3604   1.1720  2.8672 0.0041  1.0633  5.6575\n",
       "intercept         -1.1632   0.5123 -2.2702 0.0232 -2.1673 -0.1590\n",
       "=================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running logistic regression in statsmodel on the city groupings - please note\n",
    "# we're running this on the cities we used for filtering rather than the actual\n",
    "# city as there are many small cities that are lumped into the larger cities' filters\n",
    "dummy_ranks = pd.get_dummies(workdf['CityGrouping'])\n",
    "cols_to_keep = ['HighSalary']\n",
    "data = workdf[cols_to_keep].join(dummy_ranks[list(dummy_ranks.columns[1:])])\n",
    "data['intercept'] = 1.0\n",
    "train_cols = data.columns[1:]\n",
    "logit = sm.Logit(data['HighSalary'], data[train_cols])\n",
    "result = logit.fit()\n",
    "result.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.654152\n",
      "         Iterations: 35\n",
      "         Function evaluations: 36\n",
      "         Gradient evaluations: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michael/anaconda/lib/python2.7/site-packages/statsmodels/base/model.py:466: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>   <td>0.056</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>    <td>HighSalary</td>          <td>AIC:</td>        <td>279.5105</td> \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2016-07-07 17:10</td>       <td>BIC:</td>        <td>296.1499</td> \n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>         <td>206</td>        <td>Log-Likelihood:</td>   <td>-134.76</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>4</td>            <td>LL-Null:</td>       <td>-142.75</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>           <td>201</td>         <td>LLR p-value:</td>    <td>0.0030347</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>0.0000</td>           <td>Scale:</td>        <td>1.0000</td>  \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th>   <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>none</th>      <td>-0.2201</td>  <td>0.9087</td>  <td>-0.2422</td> <td>0.8086</td>   <td>-2.0010</td>   <td>1.5609</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>senior</th>    <td>1.3096</td>   <td>1.0060</td>  <td>1.3017</td>  <td>0.1930</td>   <td>-0.6622</td>   <td>3.2814</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sr</th>        <td>14.1256</td> <td>821.3902</td> <td>0.0172</td>  <td>0.9863</td> <td>-1595.7696</td> <td>1624.0208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sr.</th>       <td>-0.7626</td>  <td>1.0752</td>  <td>-0.7092</td> <td>0.4782</td>   <td>-2.8699</td>   <td>1.3447</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>-0.0105</td>  <td>0.8944</td>  <td>-0.0117</td> <td>0.9907</td>   <td>-1.7635</td>   <td>1.7426</td>  \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.056    \n",
       "Dependent Variable: HighSalary       AIC:              279.5105 \n",
       "Date:               2016-07-07 17:10 BIC:              296.1499 \n",
       "No. Observations:   206              Log-Likelihood:   -134.76  \n",
       "Df Model:           4                LL-Null:          -142.75  \n",
       "Df Residuals:       201              LLR p-value:      0.0030347\n",
       "Converged:          0.0000           Scale:            1.0000   \n",
       "----------------------------------------------------------------\n",
       "             Coef.  Std.Err.    z    P>|z|    [0.025     0.975] \n",
       "----------------------------------------------------------------\n",
       "none        -0.2201   0.9087 -0.2422 0.8086    -2.0010    1.5609\n",
       "senior       1.3096   1.0060  1.3017 0.1930    -0.6622    3.2814\n",
       "sr          14.1256 821.3902  0.0172 0.9863 -1595.7696 1624.0208\n",
       "sr.         -0.7626   1.0752 -0.7092 0.4782    -2.8699    1.3447\n",
       "intercept   -0.0105   0.8944 -0.0117 0.9907    -1.7635    1.7426\n",
       "================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This logistic regression is done on key words in teh job title to see if there is \n",
    "# any effect. As we see from the results... there is not really any effect.\n",
    "dummyWord_ranks = pd.get_dummies(workdf['WordTest'])\n",
    "cols_to_keep = ['HighSalary']\n",
    "dataWord = workdf[cols_to_keep].join(dummyWord_ranks[list(dummyWord_ranks.columns[1:])])\n",
    "dataWord['intercept'] = 1.0\n",
    "train_colsWord = dataWord.columns[1:]\n",
    "logitWord = sm.Logit(dataWord['HighSalary'], dataWord[train_colsWord])\n",
    "resultWord = logitWord.fit(method='bfgs')\n",
    "resultWord.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.563781\n",
      "         Iterations: 35\n",
      "         Function evaluations: 37\n",
      "         Gradient evaluations: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michael/anaconda/lib/python2.7/site-packages/statsmodels/base/model.py:466: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.186</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>    <td>HighSalary</td>          <td>AIC:</td>         <td>262.2778</td> \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2016-07-07 17:10</td>       <td>BIC:</td>         <td>312.1960</td> \n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>         <td>206</td>        <td>Log-Likelihood:</td>    <td>-116.14</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>             <td>14</td>            <td>LL-Null:</td>        <td>-142.75</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>           <td>191</td>         <td>LLR p-value:</td>    <td>1.7445e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>0.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>         <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>none</th>          <td>-0.2500</td>  <td>0.9649</td>  <td>-0.2590</td> <td>0.7956</td> <td>-2.1412</td> <td>1.6412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>senior</th>        <td>1.0065</td>   <td>1.0767</td>  <td>0.9348</td>  <td>0.3499</td> <td>-1.1038</td> <td>3.1168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sr</th>            <td>2.6259</td>   <td>2.4042</td>  <td>1.0922</td>  <td>0.2747</td> <td>-2.0862</td> <td>7.3380</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sr.</th>           <td>-0.6093</td>  <td>1.1856</td>  <td>-0.5139</td> <td>0.6073</td> <td>-2.9331</td> <td>1.7145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Baltimore</th>     <td>-0.1517</td>  <td>0.6839</td>  <td>-0.2218</td> <td>0.8244</td> <td>-1.4921</td> <td>1.1887</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Boston</th>        <td>1.1626</td>   <td>0.7184</td>  <td>1.6183</td>  <td>0.1056</td> <td>-0.2455</td> <td>2.5708</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Chicago</th>       <td>1.7411</td>   <td>0.6688</td>  <td>2.6035</td>  <td>0.0092</td> <td>0.4304</td>  <td>3.0519</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dallas</th>        <td>0.4199</td>   <td>0.8250</td>  <td>0.5089</td>  <td>0.6108</td> <td>-1.1971</td> <td>2.0368</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Los Angeles</th>   <td>-0.6156</td>  <td>0.9861</td>  <td>-0.6243</td> <td>0.5324</td> <td>-2.5484</td> <td>1.3171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>New York</th>      <td>1.2784</td>   <td>0.6552</td>  <td>1.9513</td>  <td>0.0510</td> <td>-0.0057</td> <td>2.5625</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Philadelphia</th>  <td>1.1155</td>   <td>0.8170</td>  <td>1.3653</td>  <td>0.1722</td> <td>-0.4858</td> <td>2.7168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Raleigh</th>       <td>0.6535</td>   <td>0.7766</td>  <td>0.8415</td>  <td>0.4001</td> <td>-0.8686</td> <td>2.1756</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>San Francisco</th> <td>2.1857</td>   <td>0.7830</td>  <td>2.7914</td>  <td>0.0052</td> <td>0.6510</td>  <td>3.7203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seattle</th>       <td>3.5346</td>   <td>1.3015</td>  <td>2.7157</td>  <td>0.0066</td> <td>0.9836</td>  <td>6.0855</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>     <td>-0.9280</td>  <td>1.0509</td>  <td>-0.8831</td> <td>0.3772</td> <td>-2.9877</td> <td>1.1316</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "=================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.186     \n",
       "Dependent Variable: HighSalary       AIC:              262.2778  \n",
       "Date:               2016-07-07 17:10 BIC:              312.1960  \n",
       "No. Observations:   206              Log-Likelihood:   -116.14   \n",
       "Df Model:           14               LL-Null:          -142.75   \n",
       "Df Residuals:       191              LLR p-value:      1.7445e-06\n",
       "Converged:          0.0000           Scale:            1.0000    \n",
       "------------------------------------------------------------------\n",
       "                Coef.   Std.Err.     z     P>|z|    [0.025  0.975]\n",
       "------------------------------------------------------------------\n",
       "none           -0.2500    0.9649  -0.2590  0.7956  -2.1412  1.6412\n",
       "senior          1.0065    1.0767   0.9348  0.3499  -1.1038  3.1168\n",
       "sr              2.6259    2.4042   1.0922  0.2747  -2.0862  7.3380\n",
       "sr.            -0.6093    1.1856  -0.5139  0.6073  -2.9331  1.7145\n",
       "Baltimore      -0.1517    0.6839  -0.2218  0.8244  -1.4921  1.1887\n",
       "Boston          1.1626    0.7184   1.6183  0.1056  -0.2455  2.5708\n",
       "Chicago         1.7411    0.6688   2.6035  0.0092   0.4304  3.0519\n",
       "Dallas          0.4199    0.8250   0.5089  0.6108  -1.1971  2.0368\n",
       "Los Angeles    -0.6156    0.9861  -0.6243  0.5324  -2.5484  1.3171\n",
       "New York        1.2784    0.6552   1.9513  0.0510  -0.0057  2.5625\n",
       "Philadelphia    1.1155    0.8170   1.3653  0.1722  -0.4858  2.7168\n",
       "Raleigh         0.6535    0.7766   0.8415  0.4001  -0.8686  2.1756\n",
       "San Francisco   2.1857    0.7830   2.7914  0.0052   0.6510  3.7203\n",
       "Seattle         3.5346    1.3015   2.7157  0.0066   0.9836  6.0855\n",
       "intercept      -0.9280    1.0509  -0.8831  0.3772  -2.9877  1.1316\n",
       "=================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining both the cities and \"expensive\" words to see how it looks.  it's just okay... \n",
    "dataFull = workdf[cols_to_keep].join(dummyWord_ranks[list(dummyWord_ranks.columns[1:])]).join(dummy_ranks[list(dummy_ranks.columns[1:])])\n",
    "dataFull['intercept'] = 1.0\n",
    "train_colsFull = dataFull.columns[1:]\n",
    "logitFull = sm.Logit(dataFull['HighSalary'], dataFull[train_colsFull])\n",
    "resultFull = logitFull.fit(method='bfgs')\n",
    "resultFull.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redoing the logistic regression models in scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setting the target and data variables to the full dataset (Using both \"good\" words and cities)\n",
    "y = dataFull['HighSalary']\n",
    "X= dataFull[train_colsFull]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       False  True \n",
       "False     24     11\n",
       "True      18     15"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running the test-train-split, fitting and predicting \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=99)\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "lr_model = lr.fit(X_train, y_train)\n",
    "lr_ypred = lr_model.predict(X_test)\n",
    "\n",
    "# Confusion matrix generation\n",
    "lr_cm = confusion_matrix(y_test, lr_ypred, labels=lr.classes_)\n",
    "lr_cm = pd.DataFrame(lr_cm, columns=lr.classes_, index=lr.classes_)\n",
    "lr_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.62      0.69      0.65        35\n",
      "       True       0.62      0.55      0.58        33\n",
      "\n",
      "avg / total       0.62      0.62      0.62        68\n",
      "\n",
      "0.475987496448\n",
      "0.617647058824\n"
     ]
    }
   ],
   "source": [
    "# Classification report generation\n",
    "print(classification_report(y_test, lr_ypred, labels=lr.classes_))\n",
    "\n",
    "# Getting the cross val score and also the accuracy score\n",
    "print(cross_val_score(lr, X, y, cv=3).mean())\n",
    "print(accuracy_score(y_test, lr_ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 and L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Looking at L1 and L2 regularization, setting both up and printing both confusion matrices\n",
    "lr1 = LogisticRegression(penalty='l1')\n",
    "lr2 = LogisticRegression(penalty='l2')\n",
    "\n",
    "lr1_model = lr1.fit(X_train, y_train)\n",
    "lr2_model = lr2.fit(X_train, y_train)\n",
    "\n",
    "y1_pred = lr1.predict(X_test)\n",
    "y2_pred = lr2.predict(X_test)\n",
    "\n",
    "cm1 = confusion_matrix(y_test, y1_pred, labels=lr1.classes_)\n",
    "cm1 = pd.DataFrame(cm1, columns=lr1.classes_, index=lr1.classes_)\n",
    "\n",
    "cm2 = confusion_matrix(y_test, y2_pred, labels=lr2.classes_)\n",
    "cm2 = pd.DataFrame(cm2, columns=lr2.classes_, index=lr2.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       False  True \n",
       "False     26      9\n",
       "True      20     13"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       False  True \n",
       "False     24     11\n",
       "True      18     15"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.59      0.86      0.70        35\n",
      "       True       0.71      0.36      0.48        33\n",
      "\n",
      "avg / total       0.65      0.62      0.59        68\n",
      "\n",
      "0.451832907076\n",
      "0.617647058824\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y1_pred, labels=lr2.classes_))\n",
    "\n",
    "# for l1 regularization\n",
    "print(cross_val_score(lr1, X, y, cv=3).mean())\n",
    "print(accuracy_score(y_test, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.59      0.86      0.70        35\n",
      "       True       0.71      0.36      0.48        33\n",
      "\n",
      "avg / total       0.65      0.62      0.59        68\n",
      "\n",
      "0.475987496448\n",
      "0.617647058824\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y2_pred, labels=lr1.classes_))\n",
    "\n",
    "# for l2 regularization\n",
    "print(cross_val_score(lr2, X, y, cv=3).mean())\n",
    "print(accuracy_score(y_test, y2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross val logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.7825594])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking a look at cross val logistic regression\n",
    "lrcv = LogisticRegressionCV(penalty='l1', solver='liblinear')\n",
    "lrcv_model = lrcv.fit(X_train, y_train)\n",
    "lrcv_ypred = lrcv_model.predict(X_test)\n",
    "lrcv_model.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       False  True \n",
       "False     24     11\n",
       "True      18     15"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix for the LogReg CV\n",
    "lrcv_cm = confusion_matrix(y_test, lrcv_ypred, labels=lrcv.classes_)\n",
    "lrcv_cm = pd.DataFrame(lrcv_cm, columns=lrcv.classes_, index=lrcv.classes_)\n",
    "lrcv_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.57      0.69      0.62        35\n",
      "       True       0.58      0.45      0.51        33\n",
      "\n",
      "avg / total       0.57      0.57      0.57        68\n",
      "\n",
      "0.509732878659\n",
      "0.573529411765\n"
     ]
    }
   ],
   "source": [
    "# Printing the classification report for the LogRegCV\n",
    "print(classification_report(y_test, lrcv_ypred, labels=lrcv.classes_))\n",
    "\n",
    "# Getting the cross val score and also the accuracy score for l1 and l2\n",
    "# for l1 regularization\n",
    "print(cross_val_score(lrcv, X, y, cv=3).mean())\n",
    "print(accuracy_score(y_test, lrcv_ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=15, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [0.0001, 0.001, 0.01, 0.1, 0.15, 0.25, 0.275, 0.33, 0.5, 0.66, 0.75, 1.0, 2.5, 5.0, 10.0, 100.0, 1000.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using grid search to find the best C Values along an array of C Values\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "C_vals = [0.0001, 0.001, 0.01, 0.1, .15, .25, .275, .33, 0.5, .66, 0.75, 1.0, 2.5, 5.0, 10.0, 100.0, 1000.0]\n",
    "penalties = ['l1','l2']\n",
    "\n",
    "gs = GridSearchCV(logreg, {'penalty': penalties, 'C': C_vals}, verbose=False, cv=15)\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.001, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       False  True \n",
       "False     32      3\n",
       "True      26      7"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=gs.best_params_['C'], penalty=gs.best_params_['penalty'])\n",
    "cv_model = logreg.fit(X_train, y_train)\n",
    "cv_pred = cv_model.predict(X_test)\n",
    "\n",
    "cm3 = confusion_matrix(y_test, cv_pred, labels=logreg.classes_)\n",
    "cm3 = pd.DataFrame(cm3, columns=logreg.classes_, index=logreg.classes_)\n",
    "\n",
    "cm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.55      0.91      0.69        35\n",
      "       True       0.70      0.21      0.33        33\n",
      "\n",
      "avg / total       0.62      0.57      0.51        68\n",
      "\n",
      "0.553282182438\n",
      "0.573529411765\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, cv_pred, labels=logreg.classes_))\n",
    "\n",
    "# Getting the cross val score and also the accuracy score\n",
    "print(cross_val_score(cv_model, X, y, cv=3).mean())\n",
    "print(accuracy_score(y_test, cv_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Features and Classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying a new set of classifications to see if they have any bearing on salaries.  In this case, we're going to see if the company itself has any significant bearing on the salary.  We'll be using a basket of the \"recruiting\" names in tech to see if they pay out better than the companies looking for candidates directly, i.e. do companies like Workbridge Associates, Staffing companies, etc advertise a premium to others in data science?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reading in the csv to start \"afresh\"... using this as a \"checkpoint\" when i have to redo calcs\n",
    "newWorkdf = pd.read_csv('SalaryInfo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Getting the median of the salary to set up the \"HighSalary\" column, also setting up and\n",
    "# then using the \"expensive\" words bucket to see if they have a bearing in job title\n",
    "SalaryMedian = newWorkdf['Salary'].median()\n",
    "newWorkdf['HighSalary']=[x>SalaryMedian for x in newWorkdf['Salary']]\n",
    "CompanyNames = ['associates','employment','staffing','search','hanley','careers', 'jobspring']\n",
    "newWorkdf['CompanyTest'] = newWorkdf['CompanyName'].apply(lambda x: words_in_string(CompanyNames,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.618203\n",
      "         Iterations: 35\n",
      "         Function evaluations: 36\n",
      "         Gradient evaluations: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michael/anaconda/lib/python2.7/site-packages/statsmodels/base/model.py:466: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.108</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>    <td>HighSalary</td>          <td>AIC:</td>         <td>270.6995</td> \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2016-07-07 17:16</td>       <td>BIC:</td>         <td>297.3225</td> \n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>         <td>206</td>        <td>Log-Likelihood:</td>    <td>-127.35</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>7</td>            <td>LL-Null:</td>        <td>-142.75</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>           <td>198</td>         <td>LLR p-value:</td>    <td>6.7696e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>0.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>        <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th>  <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C_careers</th>    <td>-3.4243</td>  <td>2.3160</td>  <td>-1.4785</td> <td>0.1393</td>  <td>-7.9635</td> <td>1.1149</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C_employment</th> <td>3.0726</td>   <td>10.1820</td> <td>0.3018</td>  <td>0.7628</td> <td>-16.8838</td> <td>23.0290</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C_hanley</th>     <td>-3.2360</td>  <td>1.1329</td>  <td>-2.8564</td> <td>0.0043</td>  <td>-5.4564</td> <td>-1.0156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C_jobspring</th>  <td>-2.6121</td>  <td>1.1861</td>  <td>-2.2023</td> <td>0.0276</td>  <td>-4.9367</td> <td>-0.2875</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C_none</th>       <td>-2.9057</td>  <td>0.8751</td>  <td>-3.3203</td> <td>0.0009</td>  <td>-4.6209</td> <td>-1.1905</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C_search</th>     <td>-1.9492</td>  <td>1.2217</td>  <td>-1.5955</td> <td>0.1106</td>  <td>-4.3438</td> <td>0.4453</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C_staffing</th>   <td>-7.4409</td>  <td>5.5888</td>  <td>-1.3314</td> <td>0.1831</td> <td>-18.3947</td> <td>3.5130</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>    <td>2.6536</td>   <td>0.8601</td>  <td>3.0852</td>  <td>0.0020</td>  <td>0.9678</td>  <td>4.3394</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "=================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.108     \n",
       "Dependent Variable: HighSalary       AIC:              270.6995  \n",
       "Date:               2016-07-07 17:16 BIC:              297.3225  \n",
       "No. Observations:   206              Log-Likelihood:   -127.35   \n",
       "Df Model:           7                LL-Null:          -142.75   \n",
       "Df Residuals:       198              LLR p-value:      6.7696e-05\n",
       "Converged:          0.0000           Scale:            1.0000    \n",
       "-----------------------------------------------------------------\n",
       "                  Coef.  Std.Err.    z    P>|z|   [0.025   0.975]\n",
       "-----------------------------------------------------------------\n",
       "C_careers        -3.4243   2.3160 -1.4785 0.1393  -7.9635  1.1149\n",
       "C_employment      3.0726  10.1820  0.3018 0.7628 -16.8838 23.0290\n",
       "C_hanley         -3.2360   1.1329 -2.8564 0.0043  -5.4564 -1.0156\n",
       "C_jobspring      -2.6121   1.1861 -2.2023 0.0276  -4.9367 -0.2875\n",
       "C_none           -2.9057   0.8751 -3.3203 0.0009  -4.6209 -1.1905\n",
       "C_search         -1.9492   1.2217 -1.5955 0.1106  -4.3438  0.4453\n",
       "C_staffing       -7.4409   5.5888 -1.3314 0.1831 -18.3947  3.5130\n",
       "intercept         2.6536   0.8601  3.0852 0.0020   0.9678  4.3394\n",
       "=================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This logistic regression is done on key words in the company name to see if there is \n",
    "# any effect.\n",
    "dummyCompany_ranks = pd.get_dummies(newWorkdf['CompanyTest'], prefix ='C')\n",
    "cols_to_keep = ['HighSalary']\n",
    "dataCompany = newWorkdf[cols_to_keep].join(dummyCompany_ranks[list(dummyCompany_ranks.columns[1:])])\n",
    "dataCompany['intercept'] = 1.0\n",
    "train_colsCompany = dataCompany.columns[1:]\n",
    "logitCompany = sm.Logit(dataCompany['HighSalary'], dataCompany[train_colsCompany])\n",
    "resultCompany = logitCompany.fit(method='bfgs')\n",
    "resultCompany.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       False  True \n",
       "False     30      5\n",
       "True      21     12"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataCompany['HighSalary']\n",
    "X= dataCompany[train_colsCompany]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=99)\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "lr_model = lr.fit(X_train, y_train)\n",
    "lr_ypred = lr_model.predict(X_test)\n",
    "\n",
    "# Confusion matrix generation\n",
    "lr_cm = confusion_matrix(y_test, lr_ypred, labels=lr.classes_)\n",
    "lr_cm = pd.DataFrame(lr_cm, columns=lr.classes_, index=lr.classes_)\n",
    "lr_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.59      0.86      0.70        35\n",
      "       True       0.71      0.36      0.48        33\n",
      "\n",
      "avg / total       0.65      0.62      0.59        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report generation\n",
    "print(classification_report(y_test, lr_ypred, labels=lr.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.572605853936\n",
      "0.617647058824\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(lr, X, y, cv=3).mean())\n",
    "print(accuracy_score(y_test, lr_ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Looking at L1 and L2 regularization\n",
    "lr1 = LogisticRegression(penalty='l1')\n",
    "lr2 = LogisticRegression(penalty='l2')\n",
    "\n",
    "lr1_model = lr1.fit(X_train, y_train)\n",
    "lr2_model = lr2.fit(X_train, y_train)\n",
    "\n",
    "y1_pred = lr1.predict(X_test)\n",
    "y2_pred = lr2.predict(X_test)\n",
    "\n",
    "cm1 = confusion_matrix(y_test, y1_pred, labels=lr1.classes_)\n",
    "cm1 = pd.DataFrame(cm1, columns=lr1.classes_, index=lr1.classes_)\n",
    "\n",
    "cm2 = confusion_matrix(y_test, y2_pred, labels=lr2.classes_)\n",
    "cm2 = pd.DataFrame(cm2, columns=lr2.classes_, index=lr2.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       False  True \n",
       "False     30      5\n",
       "True      21     12"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       False  True \n",
       "False     30      5\n",
       "True      21     12"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.563781\n",
      "         Iterations: 35\n",
      "         Function evaluations: 37\n",
      "         Gradient evaluations: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michael/anaconda/lib/python2.7/site-packages/statsmodels/base/model.py:466: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.186</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>    <td>HighSalary</td>          <td>AIC:</td>         <td>262.2778</td> \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2016-07-07 17:17</td>       <td>BIC:</td>         <td>312.1960</td> \n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>         <td>206</td>        <td>Log-Likelihood:</td>    <td>-116.14</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>             <td>14</td>            <td>LL-Null:</td>        <td>-142.75</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>           <td>191</td>         <td>LLR p-value:</td>    <td>1.7445e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>0.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>         <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>none</th>          <td>-0.2500</td>  <td>0.9649</td>  <td>-0.2590</td> <td>0.7956</td> <td>-2.1412</td> <td>1.6412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>senior</th>        <td>1.0065</td>   <td>1.0767</td>  <td>0.9348</td>  <td>0.3499</td> <td>-1.1038</td> <td>3.1168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sr</th>            <td>2.6259</td>   <td>2.4042</td>  <td>1.0922</td>  <td>0.2747</td> <td>-2.0862</td> <td>7.3380</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sr.</th>           <td>-0.6093</td>  <td>1.1856</td>  <td>-0.5139</td> <td>0.6073</td> <td>-2.9331</td> <td>1.7145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Baltimore</th>     <td>-0.1517</td>  <td>0.6839</td>  <td>-0.2218</td> <td>0.8244</td> <td>-1.4921</td> <td>1.1887</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Boston</th>        <td>1.1626</td>   <td>0.7184</td>  <td>1.6183</td>  <td>0.1056</td> <td>-0.2455</td> <td>2.5708</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Chicago</th>       <td>1.7411</td>   <td>0.6688</td>  <td>2.6035</td>  <td>0.0092</td> <td>0.4304</td>  <td>3.0519</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dallas</th>        <td>0.4199</td>   <td>0.8250</td>  <td>0.5089</td>  <td>0.6108</td> <td>-1.1971</td> <td>2.0368</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Los Angeles</th>   <td>-0.6156</td>  <td>0.9861</td>  <td>-0.6243</td> <td>0.5324</td> <td>-2.5484</td> <td>1.3171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>New York</th>      <td>1.2784</td>   <td>0.6552</td>  <td>1.9513</td>  <td>0.0510</td> <td>-0.0057</td> <td>2.5625</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Philadelphia</th>  <td>1.1155</td>   <td>0.8170</td>  <td>1.3653</td>  <td>0.1722</td> <td>-0.4858</td> <td>2.7168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Raleigh</th>       <td>0.6535</td>   <td>0.7766</td>  <td>0.8415</td>  <td>0.4001</td> <td>-0.8686</td> <td>2.1756</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>San Francisco</th> <td>2.1857</td>   <td>0.7830</td>  <td>2.7914</td>  <td>0.0052</td> <td>0.6510</td>  <td>3.7203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seattle</th>       <td>3.5346</td>   <td>1.3015</td>  <td>2.7157</td>  <td>0.0066</td> <td>0.9836</td>  <td>6.0855</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>     <td>-0.9280</td>  <td>1.0509</td>  <td>-0.8831</td> <td>0.3772</td> <td>-2.9877</td> <td>1.1316</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "=================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.186     \n",
       "Dependent Variable: HighSalary       AIC:              262.2778  \n",
       "Date:               2016-07-07 17:17 BIC:              312.1960  \n",
       "No. Observations:   206              Log-Likelihood:   -116.14   \n",
       "Df Model:           14               LL-Null:          -142.75   \n",
       "Df Residuals:       191              LLR p-value:      1.7445e-06\n",
       "Converged:          0.0000           Scale:            1.0000    \n",
       "------------------------------------------------------------------\n",
       "                Coef.   Std.Err.     z     P>|z|    [0.025  0.975]\n",
       "------------------------------------------------------------------\n",
       "none           -0.2500    0.9649  -0.2590  0.7956  -2.1412  1.6412\n",
       "senior          1.0065    1.0767   0.9348  0.3499  -1.1038  3.1168\n",
       "sr              2.6259    2.4042   1.0922  0.2747  -2.0862  7.3380\n",
       "sr.            -0.6093    1.1856  -0.5139  0.6073  -2.9331  1.7145\n",
       "Baltimore      -0.1517    0.6839  -0.2218  0.8244  -1.4921  1.1887\n",
       "Boston          1.1626    0.7184   1.6183  0.1056  -0.2455  2.5708\n",
       "Chicago         1.7411    0.6688   2.6035  0.0092   0.4304  3.0519\n",
       "Dallas          0.4199    0.8250   0.5089  0.6108  -1.1971  2.0368\n",
       "Los Angeles    -0.6156    0.9861  -0.6243  0.5324  -2.5484  1.3171\n",
       "New York        1.2784    0.6552   1.9513  0.0510  -0.0057  2.5625\n",
       "Philadelphia    1.1155    0.8170   1.3653  0.1722  -0.4858  2.7168\n",
       "Raleigh         0.6535    0.7766   0.8415  0.4001  -0.8686  2.1756\n",
       "San Francisco   2.1857    0.7830   2.7914  0.0052   0.6510  3.7203\n",
       "Seattle         3.5346    1.3015   2.7157  0.0066   0.9836  6.0855\n",
       "intercept      -0.9280    1.0509  -0.8831  0.3772  -2.9877  1.1316\n",
       "=================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining  the cities, \"company\" words, and \"expensive\" words to see how it looks.  it's just okay... \n",
    "dataFullSet = newWorkdf[cols_to_keep].join(dummyWord_ranks[list(dummyWord_ranks.columns[1:])]).join(dummy_ranks[list(dummy_ranks.columns[1:])]).join(dummyCompany_ranks[list(dummyCompany_ranks.columns[1:])])\n",
    "dataFullSet['intercept'] = 1.0\n",
    "train_colsFullSet = dataFullSet.columns[1:]\n",
    "logitFullSet = sm.Logit(dataFullSet['HighSalary'], dataFullSet[train_colsFull])\n",
    "resultFullSet = logitFullSet.fit(method='bfgs')\n",
    "resultFullSet.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       False  True \n",
       "False     24     11\n",
       "True      15     18"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataFullSet['HighSalary']\n",
    "X= dataFullSet[train_colsFullSet]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=99)\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "lr_model = lr.fit(X_train, y_train)\n",
    "lr_ypred = lr_model.predict(X_test)\n",
    "\n",
    "# Confusion matrix generation\n",
    "lr_cm = confusion_matrix(y_test, lr_ypred, labels=lr.classes_)\n",
    "lr_cm = pd.DataFrame(lr_cm, columns=lr.classes_, index=lr.classes_)\n",
    "lr_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.62      0.69      0.65        35\n",
      "       True       0.62      0.55      0.58        33\n",
      "\n",
      "avg / total       0.62      0.62      0.62        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report generation\n",
    "print(classification_report(y_test, lr_ypred, labels=lr.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45666382495\n",
      "0.617647058824\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(lr, X, y, cv=3).mean())\n",
    "print(accuracy_score(y_test, lr_ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC curve generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So after looking at several different features and combination of features, it appears that the less complicated set of features has a better cross val and accuracy score than the combination of features.  Let's take a look at ROC curves in the case of the original combination of features - \"good\" words and cities.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setting the target and data variables to the full dataset (Using both \"good\" words and cities)\n",
    "y = dataFull['HighSalary']\n",
    "X= dataFull[train_colsFull]\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr_model = lr.fit(X, y)\n",
    "predictions = lr_model.predict(X)\n",
    "\n",
    "proba = lr_model.predict_proba(X).T[1]\n",
    "roc = roc_curve(y, proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getROCcurve(roc, title='ROC Curve', xlabel ='% of False Positives', ylabel = '% of True Positives'):\n",
    "    \n",
    "    fpr, tpr, thresholds = roc\n",
    "    fig,ax = plt.subplots()\n",
    "    ax.plot(fpr, tpr, label='ROC Curve')\n",
    "    fig.set_size_inches(7, 6, forward=True)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcAAAAGJCAYAAAAdcuPXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b2ff050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getROCcurve(roc, title='Predicting High Paying Jobs', ylabel='% of Negatives as predicted',\\\n",
    "            xlabel='% of Positives as predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
