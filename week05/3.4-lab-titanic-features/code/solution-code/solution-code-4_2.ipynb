{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection Lab\n",
    "\n",
    "In this lab we will explore feature selection on the Titanic Dataset. First of all let's load a few things:\n",
    "\n",
    "- Standard packages\n",
    "- The training set from lab 2.3\n",
    "- The union we have saved in lab 2.3\n",
    "\n",
    "\n",
    "You can load the titanic data as follows:\n",
    "\n",
    "    psql -h dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com -p 5432 -U dsi_student titanic\n",
    "    password: gastudents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://dsi_student:gastudents@dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com/titanic')\n",
    "\n",
    "df = pd.read_sql('SELECT * FROM train', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5924806 ,  0.        ,  0.        , ...,  1.        ,\n",
       "         1.        , -0.50244517],\n",
       "       [ 0.63878901,  1.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.78684529],\n",
       "       [-0.2846632 ,  0.        ,  0.        , ...,  1.        ,\n",
       "         0.        , -0.48885426],\n",
       "       ..., \n",
       "       [ 0.        ,  0.        ,  0.        , ...,  1.        ,\n",
       "         0.        , -0.17626324],\n",
       "       [-0.2846632 ,  1.        ,  0.        , ...,  0.        ,\n",
       "         1.        , -0.04438104],\n",
       "       [ 0.17706291,  0.        ,  0.        , ...,  0.        ,\n",
       "         1.        , -0.49237783]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gzip\n",
    "import dill\n",
    "\n",
    "with gzip.open('/Users/michael/DSI-projects/week05/3.4-lab-titanic-features/assets/datasets/union.dill.gz') as fin:\n",
    "    union = dill.load(fin)\n",
    "    \n",
    "X = df[[u'Pclass', u'Sex', u'Age', u'SibSp', u'Parch', u'Fare', u'Embarked']]\n",
    "y = df[u'Survived']\n",
    "\n",
    "X_transf = union.fit_transform(X)\n",
    "X_transf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1 Column names\n",
    "\n",
    "Uh oh, we have lost the column names along the way! We need to manually add them:\n",
    "- age_pipe => 'scaled_age'\n",
    "- one_hot_pipe => 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S'\n",
    "- gender_pipe => 'male'\n",
    "- fare_pipe => 'scaled_fare'\n",
    "\n",
    "Now we need to:\n",
    "\n",
    "1. Create a new pandas dataframe called `Xt` with the appropriate column names and fill it with the `X_transf` data.\n",
    "2. Notice that the current pipeline complitely discards the columns: u'SibSp', u'Parch'. Stack them as they are to the new dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_age</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>male</th>\n",
       "      <th>scaled_fare</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.592481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.502445</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.638789</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.786845</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.284663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.488854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.407926</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.420730</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.407926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.486337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   scaled_age  Pclass_1  Pclass_2  Pclass_3  Embarked_C  Embarked_Q  \\\n",
       "0   -0.592481       0.0       0.0       1.0         0.0         0.0   \n",
       "1    0.638789       1.0       0.0       0.0         1.0         0.0   \n",
       "2   -0.284663       0.0       0.0       1.0         0.0         0.0   \n",
       "3    0.407926       1.0       0.0       0.0         0.0         0.0   \n",
       "4    0.407926       0.0       0.0       1.0         0.0         0.0   \n",
       "\n",
       "   Embarked_S  male  scaled_fare  SibSp  Parch  \n",
       "0         1.0   1.0    -0.502445      1      0  \n",
       "1         0.0   0.0     0.786845      1      0  \n",
       "2         1.0   0.0    -0.488854      0      0  \n",
       "3         1.0   0.0     0.420730      1      0  \n",
       "4         1.0   1.0    -0.486337      0      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_cols = ['scaled_age', 'Pclass_1', 'Pclass_2', 'Pclass_3',\n",
    "            'Embarked_C', 'Embarked_Q', 'Embarked_S',\n",
    "            'male', 'scaled_fare']\n",
    "\n",
    "Xt = pd.DataFrame(X_transf, columns=new_cols)\n",
    "Xt = pd.concat([Xt, X[[u'SibSp', u'Parch']]], axis = 1)\n",
    "Xt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature selection\n",
    "\n",
    "Let's use the `SelectKBest` method in scikit learn to see which are the top 5 features.\n",
    "\n",
    "- What are the top 5 features for `Xt`?\n",
    "\n",
    "=> store them in a variable called `kbest_columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>male</th>\n",
       "      <th>scaled_fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.502445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.786845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.488854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.420730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.486337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass_1  Pclass_3  Embarked_C  male  scaled_fare\n",
       "0       0.0       1.0         0.0   1.0    -0.502445\n",
       "1       1.0       0.0         1.0   0.0     0.786845\n",
       "2       0.0       1.0         0.0   0.0    -0.488854\n",
       "3       1.0       0.0         0.0   0.0     0.420730\n",
       "4       0.0       1.0         0.0   1.0    -0.486337"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector = SelectKBest(f_classif, k=5)\n",
    "selected_data = selector.fit_transform(Xt, y)\n",
    "kbest_columns = Xt.columns[selector.get_support()]\n",
    "Xtbest = pd.DataFrame(selected_data, columns=kbest_columns)\n",
    "Xtbest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Recursive Feature Elimination\n",
    "\n",
    "`Scikit Learn` also offers recursive feature elimination as a class named `RFECV`. Use it in combination with a logistic regression model to see what features would be kept with this method.\n",
    "\n",
    "=> store them in a variable called `rfecv_columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'scaled_age',   u'Pclass_1',   u'Pclass_2',   u'Pclass_3',\n",
       "       u'Embarked_C', u'Embarked_Q',       u'male',      u'SibSp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = LogisticRegression()\n",
    "selector = RFECV(estimator, step=1, cv=5)\n",
    "selector = selector.fit(Xt, y)\n",
    "rfecv_columns = Xt.columns[selector.support_]\n",
    "rfecv_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Logistic regression coefficients\n",
    "\n",
    "Let's see if the Logistic Regression coefficients correspond.\n",
    "\n",
    "- Create a logistic regression model\n",
    "- Perform grid search over penalty type and C strength in order to find the best parameters\n",
    "- Sort the logistic regression coefficients by absolute value. Do the top 5 correspond to those above?\n",
    "> Answer: Not completely. That could be due to scaling\n",
    "\n",
    "=> choose which ones you would keep and store them in a variable called `lr_columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GridSearchCV(LogisticRegression(), {'C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "                                            'penalty': ['l1', 'l2']})\n",
    "model.fit(Xt, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79236812570145898"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Surv coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>1.874190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass_1</th>\n",
       "      <td>0.853465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass_3</th>\n",
       "      <td>0.550361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scaled_age</th>\n",
       "      <td>0.365079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_C</th>\n",
       "      <td>0.358697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass_2</th>\n",
       "      <td>0.351926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_Q</th>\n",
       "      <td>0.250084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>0.230901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scaled_fare</th>\n",
       "      <td>0.222571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.010825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_S</th>\n",
       "      <td>0.002806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Surv coeff\n",
       "male           1.874190\n",
       "Pclass_1       0.853465\n",
       "Pclass_3       0.550361\n",
       "scaled_age     0.365079\n",
       "Embarked_C     0.358697\n",
       "Pclass_2       0.351926\n",
       "Embarked_Q     0.250084\n",
       "SibSp          0.230901\n",
       "scaled_fare    0.222571\n",
       "Parch          0.010825\n",
       "Embarked_S     0.002806"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs = pd.DataFrame(model.best_estimator_.coef_, columns = Xt.columns)\n",
    "coeffs_t = coeffs.transpose()\n",
    "coeffs_t.columns = ['Surv coeff']\n",
    "coeffs_t.abs().sort_values('Surv coeff', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# keep the ones with coeff above 0.3\n",
    "lr_columns = coeffs.columns[(coeffs.abs() > 0.3).values[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare features sets\n",
    "\n",
    "Use the `best estimator` from question 4 on the 3 different feature sets:\n",
    "\n",
    "- `kbest_columns`\n",
    "- `rfecv_columns`\n",
    "- `lr_columns`\n",
    "- `all_columns`\n",
    "\n",
    "Questions:\n",
    "\n",
    "- Which scores the highest? (use cross_val_score)\n",
    "- Is the difference significant?\n",
    "> Answer: Not really\n",
    "- discuss in pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean score</th>\n",
       "      <th>std score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>kbest</th>\n",
       "      <td>0.762065</td>\n",
       "      <td>0.027122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rfecv</th>\n",
       "      <td>0.796857</td>\n",
       "      <td>0.023056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.778900</td>\n",
       "      <td>0.022221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.792368</td>\n",
       "      <td>0.022891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean score  std score\n",
       "kbest    0.762065   0.027122\n",
       "rfecv    0.796857   0.023056\n",
       "lr       0.778900   0.022221\n",
       "all      0.792368   0.022891"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "def score(X):\n",
    "    scores = cross_val_score(model.best_estimator_, X, y)\n",
    "    return scores.mean(), scores.std()\n",
    "\n",
    "all_scores = [\n",
    "    score(Xt[kbest_columns]),\n",
    "    score(Xt[rfecv_columns]),\n",
    "    score(Xt[lr_columns]),\n",
    "    score(Xt)]\n",
    "\n",
    "pd.DataFrame(all_scores, columns=['mean score', 'std score'], index = ['kbest', 'rfecv', 'lr', 'all'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "Use a bar chart to display the logistic regression coefficients. Start from the most negative on the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x117404f90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAE1CAYAAAACmZAqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzCrsfwEaeP610PllCgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1150acad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coeffs_t.sort_values('Surv coeff').plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
