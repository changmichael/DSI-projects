{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Lab 2: MLLib\n",
    "\n",
    "In this lab we will explore the [MLLib library](https://spark.apache.org/docs/1.2.1/mllib-guide.html) for machine learning in Spark. The API of this library is very similar to Scikit Learn, and it plays quite nicely with Pandas.\n",
    "\n",
    "This lab follows quite closely [this blog post](https://www.mapr.com/blog/churn-prediction-pyspark-using-mllib-and-ml-packages), so if you're lost you can go have  look there for guidance.\n",
    "\n",
    "Let's start with the usual:\n",
    "    - vagrant up\n",
    "    - vagrant ssh\n",
    "\n",
    "You should have access to Jupyter notebook here:\n",
    "\n",
    "    http://10.211.55.101:18888/tree\n",
    "    \n",
    "The problem we will solve is the prediction of [_churn rate_](https://en.wikipedia.org/wiki/Churn_rate), which is a measure of how many customers are lost over a period of time. This is a very important business metric, in particular for large companies like Telecom companies.\n",
    "\n",
    "We will use a dataset provided by [BigML](https://bigml.com/). The data has been copied to your VM, but can also be downloaded [here](https://bml-data.s3.amazonaws.com/churn-bigml-80.csv) and [here](https://bml-data.s3.amazonaws.com/churn-bigml-20.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Disable warnings, set Matplotlib inline plotting and load Pandas package\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "pd.options.display.mpl_style = 'default'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the SparkContext and sqlContext are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.a: Load the data\n",
    "\n",
    "Let's start by loading the data. Since the input is a CSV file we'll need to provide a parser.\n",
    "\n",
    "- Use the sqlContext.read.load function to load the data\n",
    "    - load the bigml-80 file to an RDD called CV_data\n",
    "    - load the bigml-20 file to an RDD called final_test_data\n",
    "    - cache CV_data to speed up things\n",
    "    \n",
    "Note that you can print the schema of the RDD if you want to\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CV_data = sqlContext.read.load('file:///home/vagrant/data/churn/churn-bigml-80.csv', \n",
    "                          format='com.databricks.spark.csv', \n",
    "                          header='true', \n",
    "                          inferSchema='true')\n",
    "\n",
    "final_test_data = sqlContext.read.load('file:///home/vagrant/data/churn/churn-bigml-20.csv', \n",
    "                          format='com.databricks.spark.csv', \n",
    "                          header='true', \n",
    "                          inferSchema='true')\n",
    "CV_data.cache()\n",
    "CV_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.b: Quick look at the data\n",
    "\n",
    "- use the `take` function to take the first 5 lines of the `CV_data` RDD and display them as Pandas dataframe\n",
    "- use the `describe` function to have some summary statistics about the training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(CV_data.take(5), columns=CV_data.columns).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "CV_data = CV_data.withColumn(\"Account length\", CV_data[\"Account length\"].cast(IntegerType()))\n",
    "CV_data = CV_data.withColumn(\"Area code\", CV_data[\"Area Code\"].cast(IntegerType()))\n",
    "CV_data = CV_data.withColumn(\"Number vmail messages\", CV_data[\"Number vmail messages\"].cast(IntegerType()))\n",
    "CV_data = CV_data.withColumn(\"Total day minutes\", CV_data[\"Total day minutes\"].cast(DoubleType()))\n",
    "CV_data = CV_data.withColumn(\"Total day calls\", CV_data[\"Total day calls\"].cast(IntegerType()))\n",
    "CV_data = CV_data.withColumn(\"Total day charge\", CV_data[\"Total day charge\"].cast(DoubleType()))\n",
    "CV_data = CV_data.withColumn(\"Total eve minutes\", CV_data[\"Total eve minutes\"].cast(DoubleType()))\n",
    "CV_data = CV_data.withColumn(\"Total eve calls\", CV_data[\"Total eve calls\"].cast(IntegerType()))\n",
    "CV_data = CV_data.withColumn(\"Total eve charge\", CV_data[\"Total eve charge\"].cast(DoubleType()))\n",
    "CV_data = CV_data.withColumn(\"Total night minutes\", CV_data[\"Total night minutes\"].cast(DoubleType()))\n",
    "CV_data = CV_data.withColumn(\"Total night calls\", CV_data[\"Total night calls\"].cast(IntegerType()))\n",
    "CV_data = CV_data.withColumn(\"Total night charge\", CV_data[\"Total night charge\"].cast(DoubleType()))\n",
    "CV_data = CV_data.withColumn(\"Total intl minutes\", CV_data[\"Total intl minutes\"].cast(DoubleType()))\n",
    "CV_data = CV_data.withColumn(\"Total intl calls\", CV_data[\"Total intl calls\"].cast(IntegerType()))\n",
    "CV_data = CV_data.withColumn(\"Total intl charge\", CV_data[\"Total intl charge\"].cast(DoubleType()))\n",
    "CV_data = CV_data.withColumn(\"Customer service calls\", CV_data[\"Customer service calls\"].cast(IntegerType()))\n",
    "\n",
    "CV_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CV_data.describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Sample inspection\n",
    "\n",
    "Not all the features are numeric. `CV_data.dtypes` contains information on the type.\n",
    "\n",
    "- select the features that are either `int` or `double`\n",
    "- use the `sample` function to get a 10% sample of the training RDD\n",
    "- Display a Pandas.scatter_matrix of the sampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numeric_features = [t[0] for t in CV_data.dtypes if t[1] == 'int' or t[1] == 'double']\n",
    "\n",
    "sampled_data = CV_data.select(numeric_features).sample(False, 0.10).toPandas()\n",
    "\n",
    "axs = pd.scatter_matrix(sampled_data, figsize=(12, 12));\n",
    "\n",
    "# Rotate axis labels and remove axis ticks\n",
    "n = len(sampled_data.columns)\n",
    "for i in range(n):\n",
    "    v = axs[i, 0]\n",
    "    v.yaxis.label.set_rotation(0)\n",
    "    v.yaxis.label.set_ha('right')\n",
    "    v.set_yticks(())\n",
    "    h = axs[n-1, i]\n",
    "    h.xaxis.label.set_rotation(90)\n",
    "    h.set_xticks(())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Feature selection\n",
    "\n",
    "Column selection on an RDD works differently than in Scikit Learn. For example if we want to drop 2 columns in Spark, we just apply the `.drop(column)` function 2 times.\n",
    "\n",
    "- Drop the following columns:\n",
    "    - State\n",
    "    - Area Code\n",
    "    - Total day charge\n",
    "    - Total eve charge\n",
    "    - Total night charge\n",
    "    - Total intl charge\n",
    "    \n",
    "Also, we can apply a function to a column with the construct:\n",
    "\n",
    "    .withColumn('column_name', function(CV_data['column_name']))\n",
    "    \n",
    "Use it to transform binary string labels to `1.0` or `0.0`. Treat these columns:\n",
    "\n",
    "    - Churn\n",
    "    - International plan\n",
    "    - Voice mail plan\n",
    "\n",
    "You may need these two imports:\n",
    "\n",
    "```python\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "```\n",
    "\n",
    "Also, use the `.cache` function to cache your pipeline results so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "\n",
    "binary_map = {'Yes':1.0, 'No':0.0, 'True':1.0, 'False':0.0}\n",
    "toNum = UserDefinedFunction(lambda k: binary_map[k], DoubleType())\n",
    "\n",
    "CV_data = CV_data.drop('State').drop('Area code') \\\n",
    "    .drop('Total day charge').drop('Total eve charge') \\\n",
    "    .drop('Total night charge').drop('Total intl charge') \\\n",
    "    .withColumn('Churn', toNum(CV_data['Churn'])) \\\n",
    "    .withColumn('International plan', toNum(CV_data['International plan'])) \\\n",
    "    .withColumn('Voice mail plan', toNum(CV_data['Voice mail plan'])).cache()\n",
    "\n",
    "final_test_data = final_test_data.drop('State').drop('Area code') \\\n",
    "    .drop('Total day charge').drop('Total eve charge') \\\n",
    "    .drop('Total night charge').drop('Total intl charge') \\\n",
    "    .withColumn('Churn', toNum(final_test_data['Churn'])) \\\n",
    "    .withColumn('International plan', toNum(final_test_data['International plan'])) \\\n",
    "    .withColumn('Voice mail plan', toNum(final_test_data['Voice mail plan'])).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, take 5 lines and display them with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(CV_data.take(5), columns=CV_data.columns).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Train Decision Tree\n",
    "\n",
    "Time has come to do our first model using MLLib. We will use a decision tree.\n",
    "\n",
    "- [LabeledPoint](https://spark.apache.org/docs/0.8.1/api/mllib/org/apache/spark/mllib/regression/LabeledPoint.html) allows us to represent a data point with features and labels. Map it across the data using a function\n",
    "- `.randomSplit` allows us to split the data in train/test sets. Do an 80/20 split\n",
    "- Train a [DecisionTree](http://spark.apache.org/docs/latest/mllib-decision-tree.html) on the training data\n",
    "- Display the trained model using `print model.toDebugString()`\n",
    "\n",
    "You may need the following imports:\n",
    "\n",
    "```python\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.tree import DecisionTree\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.tree import DecisionTree\n",
    "\n",
    "def labelData(data):\n",
    "    # label: row[end], features: row[0:end-1]\n",
    "    return data.map(lambda row: LabeledPoint(row[-1], row[:-1]))\n",
    "\n",
    "training_data, testing_data = labelData(CV_data).randomSplit([0.8, 0.2])\n",
    "\n",
    "model = DecisionTree.trainClassifier(training_data, numClasses=2, maxDepth=2,\n",
    "                                     categoricalFeaturesInfo={1:2, 2:2},\n",
    "                                     impurity='gini', maxBins=32)\n",
    "\n",
    "print model.toDebugString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Feature 12:', CV_data.columns[12]\n",
    "print 'Feature 4: ', CV_data.columns[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Model valuation\n",
    "\n",
    "\n",
    "The MulticlassMetrics module contains a lot of metrics functions.\n",
    "\n",
    "- Evaluate the model on the test data using `.predict`\n",
    "- Calculate the following metrics:\n",
    "    - Precision of True \n",
    "    - Precision of False\n",
    "    - Recall of True    \n",
    "    - Recall of False   \n",
    "    - F-1 Score         \n",
    "    - Confusion Matrix\n",
    "\n",
    "- Finally, display how many \n",
    "\n",
    "```python\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "def getPredictionsLabels(model, test_data):\n",
    "    predictions = model.predict(test_data.map(lambda r: r.features))\n",
    "    return predictions.zip(test_data.map(lambda r: r.label))\n",
    "\n",
    "def printMetrics(predictions_and_labels):\n",
    "    metrics = MulticlassMetrics(predictions_and_labels)\n",
    "    print 'Precision of True ', metrics.precision(1)\n",
    "    print 'Precision of False', metrics.precision(0)\n",
    "    print 'Recall of True    ', metrics.recall(1)\n",
    "    print 'Recall of False   ', metrics.recall(0)\n",
    "    print 'F-1 Score         ', metrics.fMeasure()\n",
    "    print 'Confusion Matrix\\n', metrics.confusionMatrix().toArray()\n",
    "\n",
    "predictions_and_labels = getPredictionsLabels(model, testing_data)\n",
    "\n",
    "printMetrics(predictions_and_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CV_data.groupby('Churn').count().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Cross Validation\n",
    "\n",
    "The [original blog post mentioned above](https://www.mapr.com/blog/churn-prediction-pyspark-using-mllib-and-ml-packages) also contains code to implement cross validation. Try it and see if you understand how it's done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stratified_CV_data = CV_data.sampleBy('Churn', fractions={0: 388./2278, 1: 1.0}).cache()\n",
    "\n",
    "stratified_CV_data.groupby('Churn').count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data, testing_data = labelData(stratified_CV_data).randomSplit([0.8, 0.2])\n",
    "\n",
    "model = DecisionTree.trainClassifier(training_data, numClasses=2, maxDepth=2,\n",
    "                                     categoricalFeaturesInfo={1:2, 2:2},\n",
    "                                     impurity='gini', maxBins=32)\n",
    "\n",
    "predictions_and_labels = getPredictionsLabels(model, testing_data)\n",
    "printMetrics(predictions_and_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "def vectorizeData(data):\n",
    "    return data.map(lambda r: [r[-1], Vectors.dense(r[:-1])]).toDF(['label','features'])\n",
    "\n",
    "vectorized_CV_data = vectorizeData(stratified_CV_data)\n",
    "\n",
    "# Index labels, adding metadata to the label column\n",
    "labelIndexer = StringIndexer(inputCol='label',\n",
    "                             outputCol='indexedLabel').fit(vectorized_CV_data)\n",
    "\n",
    "# Automatically identify categorical features and index them\n",
    "featureIndexer = VectorIndexer(inputCol='features',\n",
    "                               outputCol='indexedFeatures',\n",
    "                               maxCategories=2).fit(vectorized_CV_data)\n",
    "\n",
    "# Train a DecisionTree model\n",
    "dTree = DecisionTreeClassifier(labelCol='indexedLabel', featuresCol='indexedFeatures')\n",
    "\n",
    "# Chain indexers and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, dTree])\n",
    "\n",
    "# Search through decision tree's maxDepth parameter for best model\n",
    "paramGrid = ParamGridBuilder().addGrid(dTree.maxDepth, [2,3,4,5,6,7]).build()\n",
    "\n",
    "# Set F-1 score as evaluation metric for best model selection\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='indexedLabel',\n",
    "                                              predictionCol='prediction', metricName='f1')    \n",
    "\n",
    "# Set up 3-fold cross validation\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=3)\n",
    "\n",
    "CV_model = crossval.fit(vectorized_CV_data)\n",
    "\n",
    "# Fetch best model\n",
    "tree_model = CV_model.bestModel.stages[2]\n",
    "print tree_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorized_test_data = vectorizeData(final_test_data)\n",
    "\n",
    "transformed_data = CV_model.transform(vectorized_test_data)\n",
    "print evaluator.getMetricName(), 'accuracy:', evaluator.evaluate(transformed_data)\n",
    "\n",
    "predictions = transformed_data.select('indexedLabel', 'prediction', 'probability')\n",
    "predictions.toPandas().head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
