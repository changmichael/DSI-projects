{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from IPython.core.display import HTML, Image\n",
    "from sklearn.metrics import precision_score, auc, recall_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Created several functions to help us with scraping, cleaning, and polishing the \n",
    "# data.  \n",
    "\n",
    "def get_soup_from_url(url):\n",
    "    # Give us beautiful soup for an url\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page,'lxml')\n",
    "    return soup\n",
    "\n",
    "def extract_location_from_result(result):\n",
    "    # Scrapes the location from a single result on the Indeed website\n",
    "    loca = result.find('span', class_ = 'location').text\n",
    "    location = loca.split(',')[0]\n",
    "    return str(location)\n",
    "\n",
    "def extract_company_from_result(result):\n",
    "    # Scrapes the company name from a single result on the Indeed website\n",
    "    if result.find('span', class_ = 'company') == None:\n",
    "        company = np.nan\n",
    "    else:\n",
    "        company = str(result.find('span', class_ = 'company').text.encode('ascii','ignore').strip())\n",
    "    return company\n",
    "\n",
    "def extract_jobtitle_from_result(result):\n",
    "    # Scrapes the job title from a single result on the Indeed website\n",
    "    jobtitle = result.find('a', class_ = 'jobtitle')\n",
    "    if jobtitle != None:\n",
    "        jobtitle = result.find('a',class_ = 'jobtitle').text.strip().encode('ascii','ignore')\n",
    "    else:\n",
    "        jobtitle = result.find('a').text.encode('ascii','ignore')\n",
    "    return str(jobtitle)\n",
    "\n",
    "def extract_salary_from_result(result):\n",
    "    # Scrapes the salary from a single result on the Indeed website\n",
    "    salary = result.find('nobr')\n",
    "    if salary != None:\n",
    "        salary = str(result.find('nobr').text)\n",
    "    else:\n",
    "        salary = np.nan\n",
    "    return (salary)\n",
    "\n",
    "def DollarDrop(x):\n",
    "    # gets rid of the special characters in a dollar amount on the Indeed website\n",
    "    y = x.split('$')\n",
    "    z = y[1].replace(',','')\n",
    "    return z\n",
    "\n",
    "def SalarySplitter(x):\n",
    "    # changes dollar amount from a string to a usable int (or nan if nothing there)\n",
    "    x = str(x)\n",
    "    a = x.strip().split(' ')\n",
    "    tenor = a[-1]\n",
    "    if tenor == 'year':\n",
    "        if a[1] == '-':\n",
    "            salary = (int(DollarDrop(a[0])) + int(DollarDrop(a[2])))/2\n",
    "        else:\n",
    "            salary = int(DollarDrop(a[0]))\n",
    "    else:\n",
    "        salary = np.nan\n",
    "    return salary\n",
    "\n",
    "def words_in_string(wordList, x):\n",
    "    # matches the words for the word filter in lowercase letters\n",
    "    for word in x.split():\n",
    "        if word.lower() in wordList:\n",
    "            return word.lower()\n",
    "    return 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  Setting up a loop to take in several cities with max results to scrape for data\n",
    "url_template = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l={city}&start={start}\"\n",
    "max_results_per_city = 300\n",
    "\n",
    "results = []\n",
    "\n",
    "for city in set(['New+York', 'Chicago', 'Los+Angeles', 'Seattle', 'San+Francisco', 'Baltimore', 'Atlanta', 'Boston', \n",
    "                 'Dallas', 'Raleigh', 'Philadelphia']):\n",
    "    url_prep = (url_template.replace('{city}',city))\n",
    "    for start in range(0, max_results_per_city, 10):\n",
    "        url = url_prep.replace('{start}',str(start))\n",
    "        # Grabbing the results from the request (as above) with multiple cities then \n",
    "        # appending the full set of data to the results list\n",
    "        soup = get_soup_from_url(url)\n",
    "        for element in soup.findAll('div',class_ = 'result'):\n",
    "            preResult=[]\n",
    "            preResult.append(extract_jobtitle_from_result(element))\n",
    "            preResult.append(extract_company_from_result(element))\n",
    "            preResult.append(extract_location_from_result(element))\n",
    "            cityTag = city.replace('+',' ')\n",
    "            preResult.append(cityTag)\n",
    "            preResult.append(extract_salary_from_result(element))\n",
    "            results.append(preResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Making a dataframe out of results complete with new column names, also making the numbers in salary\n",
    "# ints instead of strings.  Finally dropping all na rows as we're interested in the rows with \n",
    "# salary information.\n",
    "df = pd.DataFrame(results, columns  = ['JobTitle', 'CompanyName', 'City', 'CityGrouping', 'Salary'])\n",
    "df['Salary'] = df['Salary'].apply(lambda x: SalarySplitter(x))\n",
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  Saving the dataframe to a csv file.  Important as it takes 2-3 minutes to do the scrape...\n",
    "df.to_csv('SalaryInfo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reading in the csv... using this as a \"checkpoint\" when i have to redo calcs\n",
    "workdf = pd.read_csv('SalaryInfo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Getting the median of the salary to set up the \"HighSalary\" column, also setting up and\n",
    "# then using the \"expensive\" words bucket to see if they have a bearing in job title\n",
    "SalaryMedian = workdf['Salary'].median()\n",
    "workdf['HighSalary']=[x>SalaryMedian for x in workdf['Salary']]\n",
    "ExpensiveWords = ['senior', 'sr.', 'sr', 'manager']\n",
    "workdf['WordTest'] = workdf['JobTitle'].apply(lambda x: words_in_string(ExpensiveWords,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.584500\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.157</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>    <td>HighSalary</td>          <td>AIC:</td>         <td>262.8138</td> \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2016-07-07 00:43</td>       <td>BIC:</td>         <td>299.4205</td> \n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>         <td>206</td>        <td>Log-Likelihood:</td>    <td>-120.41</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>             <td>10</td>            <td>LL-Null:</td>        <td>-142.75</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>           <td>195</td>         <td>LLR p-value:</td>    <td>2.4784e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>         <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Baltimore</th>     <td>-0.1490</td>  <td>0.6662</td>  <td>-0.2237</td> <td>0.8230</td> <td>-1.4548</td> <td>1.1567</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Boston</th>        <td>1.4816</td>   <td>0.6917</td>  <td>2.1421</td>  <td>0.0322</td> <td>0.1260</td>  <td>2.8373</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Chicago</th>       <td>2.0794</td>   <td>0.6614</td>  <td>3.1438</td>  <td>0.0017</td> <td>0.7830</td>  <td>3.3758</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dallas</th>        <td>0.4700</td>   <td>0.7984</td>  <td>0.5887</td>  <td>0.5561</td> <td>-1.0949</td> <td>2.0349</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Los Angeles</th>   <td>-0.3409</td>  <td>0.9347</td>  <td>-0.3648</td> <td>0.7153</td> <td>-2.1728</td> <td>1.4910</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>New York</th>      <td>1.4508</td>   <td>0.6390</td>  <td>2.2704</td>  <td>0.0232</td> <td>0.1984</td>  <td>2.7033</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Philadelphia</th>  <td>1.3455</td>   <td>0.7932</td>  <td>1.6963</td>  <td>0.0898</td> <td>-0.2092</td> <td>2.9001</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Raleigh</th>       <td>0.8755</td>   <td>0.7444</td>  <td>1.1760</td>  <td>0.2396</td> <td>-0.5836</td> <td>2.3345</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>San Francisco</th> <td>2.4849</td>   <td>0.7610</td>  <td>3.2652</td>  <td>0.0011</td> <td>0.9933</td>  <td>3.9765</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seattle</th>       <td>3.3604</td>   <td>1.1720</td>  <td>2.8672</td>  <td>0.0041</td> <td>1.0633</td>  <td>5.6575</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>     <td>-1.1632</td>  <td>0.5123</td>  <td>-2.2702</td> <td>0.0232</td> <td>-2.1673</td> <td>-0.1590</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "=================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.157     \n",
       "Dependent Variable: HighSalary       AIC:              262.8138  \n",
       "Date:               2016-07-07 00:43 BIC:              299.4205  \n",
       "No. Observations:   206              Log-Likelihood:   -120.41   \n",
       "Df Model:           10               LL-Null:          -142.75   \n",
       "Df Residuals:       195              LLR p-value:      2.4784e-06\n",
       "Converged:          1.0000           Scale:            1.0000    \n",
       "No. Iterations:     6.0000                                       \n",
       "-----------------------------------------------------------------\n",
       "                   Coef.  Std.Err.    z    P>|z|   [0.025  0.975]\n",
       "-----------------------------------------------------------------\n",
       "Baltimore         -0.1490   0.6662 -0.2237 0.8230 -1.4548  1.1567\n",
       "Boston             1.4816   0.6917  2.1421 0.0322  0.1260  2.8373\n",
       "Chicago            2.0794   0.6614  3.1438 0.0017  0.7830  3.3758\n",
       "Dallas             0.4700   0.7984  0.5887 0.5561 -1.0949  2.0349\n",
       "Los Angeles       -0.3409   0.9347 -0.3648 0.7153 -2.1728  1.4910\n",
       "New York           1.4508   0.6390  2.2704 0.0232  0.1984  2.7033\n",
       "Philadelphia       1.3455   0.7932  1.6963 0.0898 -0.2092  2.9001\n",
       "Raleigh            0.8755   0.7444  1.1760 0.2396 -0.5836  2.3345\n",
       "San Francisco      2.4849   0.7610  3.2652 0.0011  0.9933  3.9765\n",
       "Seattle            3.3604   1.1720  2.8672 0.0041  1.0633  5.6575\n",
       "intercept         -1.1632   0.5123 -2.2702 0.0232 -2.1673 -0.1590\n",
       "=================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running logistic regression in statsmodel on the city groupings - please note\n",
    "# we're running this on the cities we used for filtering rather than the actual\n",
    "# city as there are many small cities that are lumped into the larger cities' filters\n",
    "dummy_ranks = pd.get_dummies(workdf['CityGrouping'])\n",
    "cols_to_keep = ['HighSalary']\n",
    "data = workdf[cols_to_keep].join(dummy_ranks[list(dummy_ranks.columns[1:])])\n",
    "data['intercept'] = 1.0\n",
    "train_cols = data.columns[1:]\n",
    "logit = sm.Logit(data['HighSalary'], data[train_cols])\n",
    "result = logit.fit()\n",
    "result.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.654152\n",
      "         Iterations: 35\n",
      "         Function evaluations: 36\n",
      "         Gradient evaluations: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michael/anaconda/lib/python2.7/site-packages/statsmodels/base/model.py:466: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>   <td>0.056</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>    <td>HighSalary</td>          <td>AIC:</td>        <td>279.5105</td> \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2016-07-07 00:43</td>       <td>BIC:</td>        <td>296.1499</td> \n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>         <td>206</td>        <td>Log-Likelihood:</td>   <td>-134.76</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>4</td>            <td>LL-Null:</td>       <td>-142.75</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>           <td>201</td>         <td>LLR p-value:</td>    <td>0.0030347</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>0.0000</td>           <td>Scale:</td>        <td>1.0000</td>  \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th>   <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>none</th>      <td>-0.2201</td>  <td>0.9087</td>  <td>-0.2422</td> <td>0.8086</td>   <td>-2.0010</td>   <td>1.5609</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>senior</th>    <td>1.3096</td>   <td>1.0060</td>  <td>1.3017</td>  <td>0.1930</td>   <td>-0.6622</td>   <td>3.2814</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sr</th>        <td>14.1256</td> <td>821.3902</td> <td>0.0172</td>  <td>0.9863</td> <td>-1595.7696</td> <td>1624.0208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sr.</th>       <td>-0.7626</td>  <td>1.0752</td>  <td>-0.7092</td> <td>0.4782</td>   <td>-2.8699</td>   <td>1.3447</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>-0.0105</td>  <td>0.8944</td>  <td>-0.0117</td> <td>0.9907</td>   <td>-1.7635</td>   <td>1.7426</td>  \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.056    \n",
       "Dependent Variable: HighSalary       AIC:              279.5105 \n",
       "Date:               2016-07-07 00:43 BIC:              296.1499 \n",
       "No. Observations:   206              Log-Likelihood:   -134.76  \n",
       "Df Model:           4                LL-Null:          -142.75  \n",
       "Df Residuals:       201              LLR p-value:      0.0030347\n",
       "Converged:          0.0000           Scale:            1.0000   \n",
       "----------------------------------------------------------------\n",
       "             Coef.  Std.Err.    z    P>|z|    [0.025     0.975] \n",
       "----------------------------------------------------------------\n",
       "none        -0.2201   0.9087 -0.2422 0.8086    -2.0010    1.5609\n",
       "senior       1.3096   1.0060  1.3017 0.1930    -0.6622    3.2814\n",
       "sr          14.1256 821.3902  0.0172 0.9863 -1595.7696 1624.0208\n",
       "sr.         -0.7626   1.0752 -0.7092 0.4782    -2.8699    1.3447\n",
       "intercept   -0.0105   0.8944 -0.0117 0.9907    -1.7635    1.7426\n",
       "================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This logistic regression is done on key words in teh job title to see if there is \n",
    "# any effect. As we see from the results... there is not really any effect.\n",
    "dummyWord_ranks = pd.get_dummies(workdf['WordTest'])\n",
    "cols_to_keep = ['HighSalary']\n",
    "dataWord = workdf[cols_to_keep].join(dummyWord_ranks[list(dummyWord_ranks.columns[1:])])\n",
    "dataWord['intercept'] = 1.0\n",
    "train_colsWord = dataWord.columns[1:]\n",
    "logitWord = sm.Logit(dataWord['HighSalary'], dataWord[train_colsWord])\n",
    "resultWord = logitWord.fit(method='bfgs')\n",
    "resultWord.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.563781\n",
      "         Iterations: 35\n",
      "         Function evaluations: 37\n",
      "         Gradient evaluations: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michael/anaconda/lib/python2.7/site-packages/statsmodels/base/model.py:466: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.186</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>    <td>HighSalary</td>          <td>AIC:</td>         <td>262.2778</td> \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2016-07-07 00:43</td>       <td>BIC:</td>         <td>312.1960</td> \n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>         <td>206</td>        <td>Log-Likelihood:</td>    <td>-116.14</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>             <td>14</td>            <td>LL-Null:</td>        <td>-142.75</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>           <td>191</td>         <td>LLR p-value:</td>    <td>1.7445e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>0.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>         <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>none</th>          <td>-0.2500</td>  <td>0.9649</td>  <td>-0.2590</td> <td>0.7956</td> <td>-2.1412</td> <td>1.6412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>senior</th>        <td>1.0065</td>   <td>1.0767</td>  <td>0.9348</td>  <td>0.3499</td> <td>-1.1038</td> <td>3.1168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sr</th>            <td>2.6259</td>   <td>2.4042</td>  <td>1.0922</td>  <td>0.2747</td> <td>-2.0862</td> <td>7.3380</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sr.</th>           <td>-0.6093</td>  <td>1.1856</td>  <td>-0.5139</td> <td>0.6073</td> <td>-2.9331</td> <td>1.7145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Baltimore</th>     <td>-0.1517</td>  <td>0.6839</td>  <td>-0.2218</td> <td>0.8244</td> <td>-1.4921</td> <td>1.1887</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Boston</th>        <td>1.1626</td>   <td>0.7184</td>  <td>1.6183</td>  <td>0.1056</td> <td>-0.2455</td> <td>2.5708</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Chicago</th>       <td>1.7411</td>   <td>0.6688</td>  <td>2.6035</td>  <td>0.0092</td> <td>0.4304</td>  <td>3.0519</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dallas</th>        <td>0.4199</td>   <td>0.8250</td>  <td>0.5089</td>  <td>0.6108</td> <td>-1.1971</td> <td>2.0368</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Los Angeles</th>   <td>-0.6156</td>  <td>0.9861</td>  <td>-0.6243</td> <td>0.5324</td> <td>-2.5484</td> <td>1.3171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>New York</th>      <td>1.2784</td>   <td>0.6552</td>  <td>1.9513</td>  <td>0.0510</td> <td>-0.0057</td> <td>2.5625</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Philadelphia</th>  <td>1.1155</td>   <td>0.8170</td>  <td>1.3653</td>  <td>0.1722</td> <td>-0.4858</td> <td>2.7168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Raleigh</th>       <td>0.6535</td>   <td>0.7766</td>  <td>0.8415</td>  <td>0.4001</td> <td>-0.8686</td> <td>2.1756</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>San Francisco</th> <td>2.1857</td>   <td>0.7830</td>  <td>2.7914</td>  <td>0.0052</td> <td>0.6510</td>  <td>3.7203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seattle</th>       <td>3.5346</td>   <td>1.3015</td>  <td>2.7157</td>  <td>0.0066</td> <td>0.9836</td>  <td>6.0855</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>     <td>-0.9280</td>  <td>1.0509</td>  <td>-0.8831</td> <td>0.3772</td> <td>-2.9877</td> <td>1.1316</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "=================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.186     \n",
       "Dependent Variable: HighSalary       AIC:              262.2778  \n",
       "Date:               2016-07-07 00:43 BIC:              312.1960  \n",
       "No. Observations:   206              Log-Likelihood:   -116.14   \n",
       "Df Model:           14               LL-Null:          -142.75   \n",
       "Df Residuals:       191              LLR p-value:      1.7445e-06\n",
       "Converged:          0.0000           Scale:            1.0000    \n",
       "------------------------------------------------------------------\n",
       "                Coef.   Std.Err.     z     P>|z|    [0.025  0.975]\n",
       "------------------------------------------------------------------\n",
       "none           -0.2500    0.9649  -0.2590  0.7956  -2.1412  1.6412\n",
       "senior          1.0065    1.0767   0.9348  0.3499  -1.1038  3.1168\n",
       "sr              2.6259    2.4042   1.0922  0.2747  -2.0862  7.3380\n",
       "sr.            -0.6093    1.1856  -0.5139  0.6073  -2.9331  1.7145\n",
       "Baltimore      -0.1517    0.6839  -0.2218  0.8244  -1.4921  1.1887\n",
       "Boston          1.1626    0.7184   1.6183  0.1056  -0.2455  2.5708\n",
       "Chicago         1.7411    0.6688   2.6035  0.0092   0.4304  3.0519\n",
       "Dallas          0.4199    0.8250   0.5089  0.6108  -1.1971  2.0368\n",
       "Los Angeles    -0.6156    0.9861  -0.6243  0.5324  -2.5484  1.3171\n",
       "New York        1.2784    0.6552   1.9513  0.0510  -0.0057  2.5625\n",
       "Philadelphia    1.1155    0.8170   1.3653  0.1722  -0.4858  2.7168\n",
       "Raleigh         0.6535    0.7766   0.8415  0.4001  -0.8686  2.1756\n",
       "San Francisco   2.1857    0.7830   2.7914  0.0052   0.6510  3.7203\n",
       "Seattle         3.5346    1.3015   2.7157  0.0066   0.9836  6.0855\n",
       "intercept      -0.9280    1.0509  -0.8831  0.3772  -2.9877  1.1316\n",
       "=================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining both the cities and \"expensive\" words to see how it looks.  it's just okay... \n",
    "dataFull = workdf[cols_to_keep].join(dummyWord_ranks[list(dummyWord_ranks.columns[1:])]).join(dummy_ranks[list(dummy_ranks.columns[1:])])\n",
    "dataFull['intercept'] = 1.0\n",
    "train_colsFull = dataFull.columns[1:]\n",
    "logitFull = sm.Logit(dataFull['HighSalary'], dataFull[train_colsFull])\n",
    "resultFull = logitFull.fit(method='bfgs')\n",
    "resultFull.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redoing the logistic regression models in scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setting the target and data variables\n",
    "y = dataFull['HighSalary']\n",
    "X= dataFull[train_colsFull]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Running the test-train-split, fitting and predicting \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=99)\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "lr_model = lr.fit(X_train, y_train)\n",
    "lr_ypred = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       False  True \n",
       "False     24     11\n",
       "True      18     15"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix generation\n",
    "lr_cm = confusion_matrix(y_test, lr_ypred, labels=lr.classes_)\n",
    "lr_cm = pd.DataFrame(lr_cm, columns=lr.classes_, index=lr.classes_)\n",
    "lr_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.57      0.69      0.62        35\n",
      "       True       0.58      0.45      0.51        33\n",
      "\n",
      "avg / total       0.57      0.57      0.57        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report generation\n",
    "print(classification_report(y_test, lr_ypred, labels=lr.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.475987496448\n",
      "0.573529411765\n"
     ]
    }
   ],
   "source": [
    "# Getting the cross val score and also the accuracy score\n",
    "print(cross_val_score(lr, X, y, cv=3).mean())\n",
    "print(accuracy_score(y_test, lr_ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Looking at L1 and L2 regularization\n",
    "lr1 = LogisticRegression(penalty='l1')\n",
    "lr2 = LogisticRegression(penalty='l2')\n",
    "\n",
    "lr1_model = lr1.fit(X_train, y_train)\n",
    "lr2_model = lr2.fit(X_train, y_train)\n",
    "\n",
    "y1_pred = lr1.predict(X_test)\n",
    "y2_pred = lr2.predict(X_test)\n",
    "\n",
    "cm1 = confusion_matrix(y_test, y1_pred, labels=lr1.classes_)\n",
    "cm1 = pd.DataFrame(cm1, columns=lr1.classes_, index=lr1.classes_)\n",
    "\n",
    "cm2 = confusion_matrix(y_test, y2_pred, labels=lr2.classes_)\n",
    "cm2 = pd.DataFrame(cm2, columns=lr2.classes_, index=lr2.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       False  True \n",
       "False     26      9\n",
       "True      20     13"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       False  True \n",
       "False     24     11\n",
       "True      18     15"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.57      0.74      0.64        35\n",
      "       True       0.59      0.39      0.47        33\n",
      "\n",
      "avg / total       0.58      0.57      0.56        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y1_pred, labels=lr2.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.57      0.69      0.62        35\n",
      "       True       0.58      0.45      0.51        33\n",
      "\n",
      "avg / total       0.57      0.57      0.57        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y2_pred, labels=lr1.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.7825594])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking a look at cross val logistic regression\n",
    "lrcv = LogisticRegressionCV(penalty='l1', solver='liblinear')\n",
    "lrcv_model = lrcv.fit(X_train, y_train)\n",
    "lrcv_ypred = lrcv_model.predict(X_test)\n",
    "lrcv_model.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       False  True \n",
       "False     24     11\n",
       "True      18     15"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrcv_cm = confusion_matrix(y_test, lrcv_ypred, labels=lrcv.classes_)\n",
    "lrcv_cm = pd.DataFrame(lrcv_cm, columns=lrcv.classes_, index=lrcv.classes_)\n",
    "lrcv_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.57      0.69      0.62        35\n",
      "       True       0.58      0.45      0.51        33\n",
      "\n",
      "avg / total       0.57      0.57      0.57        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, lrcv_ypred, labels=lrcv.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=15, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [0.0001, 0.001, 0.01, 0.1, 0.15, 0.25, 0.275, 0.33, 0.5, 0.66, 0.75, 1.0, 2.5, 5.0, 10.0, 100.0, 1000.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using grid search to find the best C Values\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "C_vals = [0.0001, 0.001, 0.01, 0.1, .15, .25, .275, .33, 0.5, .66, 0.75, 1.0, 2.5, 5.0, 10.0, 100.0, 1000.0]\n",
    "penalties = ['l1','l2']\n",
    "\n",
    "gs = GridSearchCV(logreg, {'penalty': penalties, 'C': C_vals}, verbose=False, cv=15)\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.001, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=gs.best_params_['C'], penalty=gs.best_params_['penalty'])\n",
    "cv_model = logreg.fit(X_train, y_train)\n",
    "cv_pred = cv_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm3 = confusion_matrix(y_test, cv_pred, labels=logreg.classes_)\n",
    "cm3 = pd.DataFrame(cm3, columns=logreg.classes_, index=logreg.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       False  True \n",
       "False     32      3\n",
       "True      26      7"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.55      0.91      0.69        35\n",
      "       True       0.70      0.21      0.33        33\n",
      "\n",
      "avg / total       0.62      0.57      0.51        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, cv_pred, labels=logreg.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
