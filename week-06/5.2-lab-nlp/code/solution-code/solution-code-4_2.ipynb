{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing Lab\n",
    "\n",
    "In this lab we will further explore Scikit's and NLTK's capabilities to process text. We will use the 20 Newsgroup dataset, which is provided by Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b0bb37b2d44a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfetch_20newsgroups\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "categories = [\n",
    "    'alt.atheism',\n",
    "    'talk.religion.misc',\n",
    "    'comp.graphics',\n",
    "    'sci.space',\n",
    "]\n",
    "\n",
    "data_train = fetch_20newsgroups(subset='train', categories=categories,\n",
    "                                shuffle=True, random_state=42,\n",
    "                                remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "data_test = fetch_20newsgroups(subset='test', categories=categories,\n",
    "                               shuffle=True, random_state=42,\n",
    "                               remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data inspection\n",
    "\n",
    "We have downloaded a few newsgroup categories and removed headers, footers and quotes.\n",
    "\n",
    "Let's inspect them.\n",
    "\n",
    "1. What data taype is `data_train`\n",
    "> sklearn.datasets.base.Bunch\n",
    "- Is it like a list? Or like a Dictionary? or what?\n",
    "> Dict\n",
    "- How many data points does it contain?\n",
    "- Inspect the first data point, what does it look like?\n",
    "> A blurb of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.datasets.base.Bunch"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['description', 'DESCR', 'filenames', 'target_names', 'data', 'target']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2034"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_train['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2034"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"Hi,\\n\\nI've noticed that if you only save a model (with all your mapping planes\\npositioned carefully) to a .3DS file that when you reload it after restarting\\n3DS, they are given a default position and orientation.  But if you save\\nto a .PRJ file their positions/orientation are preserved.  Does anyone\\nknow why this information is not stored in the .3DS file?  Nothing is\\nexplicitly said in the manual about saving texture rules in the .PRJ file. \\nI'd like to be able to read the texture rule information, does anyone have \\nthe format for the .PRJ file?\\n\\nIs the .CEL file format available from somewhere?\\n\\nRych\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['data'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bag of Words model\n",
    "\n",
    "Let's train a model using a simple count vectorizer\n",
    "\n",
    "1. Initialize a standard CountVectorizer and fit the training data\n",
    "- how big is the feature dictionary\n",
    "- repeat eliminating english stop words\n",
    "- is the dictionary smaller?\n",
    "- transform the training data using the trained vectorizer\n",
    "- what are the 20 words that are most common in the whole corpus?\n",
    "- what are the 20 most common words in each of the 4 classes?\n",
    "- evaluate the performance of a Lotistic Regression on the features extracted by the CountVectorizer\n",
    "    - you will have to transform the test_set too. Be carefule to use the trained vectorizer, without re-fitting it\n",
    "- try the following 3 modification:\n",
    "    - restrict the max_features\n",
    "    - change max_df and min_df\n",
    "    - use a fixed vocabulary of size 80 combining the 20 most common words per group found earlier\n",
    "- for each of the above print a confusion matrix and investigate what gets mixed\n",
    "> Anwer: not surprisingly if we reduce the feature space we lose accuracy\n",
    "- print out the number of features for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec = CountVectorizer()\n",
    "cvec.fit(data_train['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26879"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26577"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec = CountVectorizer(stop_words='english')\n",
    "cvec.fit(data_train['data'])\n",
    "len(cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(cvec.transform(data_train['data']).todense(),\n",
    "                       columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "space       1061\n",
       "people       793\n",
       "god          745\n",
       "don          730\n",
       "like         682\n",
       "just         675\n",
       "does         600\n",
       "know         592\n",
       "think        584\n",
       "time         546\n",
       "image        534\n",
       "edu          501\n",
       "use          468\n",
       "good         449\n",
       "data         444\n",
       "nasa         419\n",
       "graphics     414\n",
       "jesus        411\n",
       "say          409\n",
       "way          387\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = X_train.sum(axis=0)\n",
    "word_counts.sort_values(ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = data_train['target_names']\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = data_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism most common words\n",
      "god         405\n",
      "people      330\n",
      "don         262\n",
      "think       215\n",
      "just        209\n",
      "does        207\n",
      "atheism     199\n",
      "say         174\n",
      "believe     163\n",
      "like        162\n",
      "atheists    162\n",
      "religion    156\n",
      "jesus       155\n",
      "know        154\n",
      "argument    148\n",
      "time        135\n",
      "said        131\n",
      "true        131\n",
      "bible       121\n",
      "way         120\n",
      "dtype: int64\n",
      "\n",
      "comp.graphics most common words\n",
      "image        484\n",
      "graphics     410\n",
      "edu          297\n",
      "jpeg         267\n",
      "file         265\n",
      "use          225\n",
      "data         219\n",
      "files        217\n",
      "images       212\n",
      "software     212\n",
      "program      199\n",
      "ftp          189\n",
      "available    185\n",
      "format       178\n",
      "color        174\n",
      "like         167\n",
      "know         165\n",
      "pub          161\n",
      "gif          160\n",
      "does         157\n",
      "dtype: int64\n",
      "\n",
      "sci.space most common words\n",
      "space        989\n",
      "nasa         374\n",
      "launch       267\n",
      "earth        222\n",
      "like         222\n",
      "data         216\n",
      "orbit        201\n",
      "time         197\n",
      "shuttle      192\n",
      "just         189\n",
      "satellite    187\n",
      "lunar        182\n",
      "moon         168\n",
      "new          158\n",
      "program      156\n",
      "don          151\n",
      "year         146\n",
      "people       142\n",
      "mission      141\n",
      "use          134\n",
      "dtype: int64\n",
      "\n",
      "talk.religion.misc most common words\n",
      "god          329\n",
      "people       267\n",
      "jesus        256\n",
      "don          162\n",
      "bible        160\n",
      "just         159\n",
      "christian    151\n",
      "think        151\n",
      "say          149\n",
      "know         149\n",
      "does         147\n",
      "did          132\n",
      "like         131\n",
      "good         131\n",
      "life         118\n",
      "way          118\n",
      "believe      117\n",
      "said         103\n",
      "point        101\n",
      "time          99\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "common_words = []\n",
    "for i in xrange(4):\n",
    "    word_count = X_train[y_train==i].sum(axis=0)\n",
    "    print names[i], \"most common words\"\n",
    "    cw = word_count.sort_values(ascending = False).head(20)\n",
    "#     cw.to_csv('../../../5.2-lesson/assets/datasets/'+names[i]+'_most_common_words.csv')\n",
    "    print cw\n",
    "    common_words.extend(cw.index)\n",
    "    print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(cvec.transform(data_test['data']).todense(),\n",
    "                      columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = data_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.745750184774575"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def docm(y_true, y_pred, labels=None):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    if labels is not None:\n",
    "        cols = ['p_'+c for c in labels]\n",
    "        df = pd.DataFrame(cm, index=labels, columns=cols)\n",
    "    else:\n",
    "        cols = ['p_'+str(i) for i in xrange(len(cm))]\n",
    "        df = pd.DataFrame(cm, columns=cols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69623059867\n",
      "Number of features: 1000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(CountVectorizer(stop_words='english',\n",
    "                                      max_features=1000),\n",
    "                      LogisticRegression(),\n",
    "                      )\n",
    "model.fit(data_train['data'], y_train)\n",
    "y_pred = model.predict(data_test['data'])\n",
    "print accuracy_score(y_test, y_pred)\n",
    "docm(y_test, y_pred, names)\n",
    "print \"Number of features:\", len(model.steps[0][1].get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.650406504065\n",
      "Number of features: 258\n"
     ]
    }
   ],
   "source": [
    "model = make_pipeline(CountVectorizer(stop_words='english',\n",
    "                                      max_features=1000,\n",
    "                                      min_df=0.03),\n",
    "                      LogisticRegression(),\n",
    "                      )\n",
    "model.fit(data_train['data'], y_train)\n",
    "y_pred = model.predict(data_test['data'])\n",
    "print accuracy_score(y_test, y_pred)\n",
    "docm(y_test, y_pred, names)\n",
    "print \"Number of features:\", len(model.steps[0][1].get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.589061345159\n",
      "Number of features: 54\n"
     ]
    }
   ],
   "source": [
    "model = make_pipeline(CountVectorizer(stop_words='english',\n",
    "                                      vocabulary=set(common_words)),\n",
    "                      LogisticRegression(),\n",
    "                      )\n",
    "model.fit(data_train['data'], y_train)\n",
    "y_pred = model.predict(data_test['data'])\n",
    "print accuracy_score(y_test, y_pred)\n",
    "docm(y_test, y_pred, names)\n",
    "print \"Number of features:\", len(model.steps[0][1].get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hashing and TF-IDF\n",
    "\n",
    "Let's see if Hashing or TF-IDF improves the accuracy.\n",
    "\n",
    "1. Initialize a HashingVectorizer and repeat the test with no restriction on the number of features\n",
    "- does the score improve with respect to the count vectorizer?\n",
    "    - can you change any of the default parameters to improve it?\n",
    "- print out the number of features for this model\n",
    "- Initialize a TF-IDF Vectorizer and repeat the analysis above\n",
    "- can you improve on your best score above?\n",
    "    - can you change any of the default parameters to improve it?\n",
    "- print out the number of features for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.743532889874\n",
      "Number of features: 65536\n"
     ]
    }
   ],
   "source": [
    "model = make_pipeline(HashingVectorizer(stop_words='english',\n",
    "                                        non_negative=True,\n",
    "                                        n_features=2**16),\n",
    "                      LogisticRegression(),\n",
    "                      )\n",
    "model.fit(data_train['data'], y_train)\n",
    "y_pred = model.predict(data_test['data'])\n",
    "print accuracy_score(y_test, y_pred)\n",
    "docm(y_test, y_pred, names)\n",
    "print \"Number of features:\", 2**16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.728011825573\n",
      "Number of features: 1000\n"
     ]
    }
   ],
   "source": [
    "model = make_pipeline(TfidfVectorizer(stop_words='english',\n",
    "                                      sublinear_tf=True,\n",
    "                                      max_df=0.5,\n",
    "                                      max_features=1000),\n",
    "                      LogisticRegression(),\n",
    "                      )\n",
    "model.fit(data_train['data'], y_train)\n",
    "y_pred = model.predict(data_test['data'])\n",
    "print accuracy_score(y_test, y_pred)\n",
    "docm(y_test, y_pred, names)\n",
    "print \"Number of features:\", len(model.steps[0][1].get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Classifier comparison\n",
    "\n",
    "Of all the vectorizers tested above, choose one that has a reasonable performance with a manageable number of features and compare the performance of these models:\n",
    "\n",
    "- KNN\n",
    "- Logistic Regression\n",
    "- Decision Trees\n",
    "- Support Vector Machine\n",
    "- Random Forest\n",
    "- Extra Trees\n",
    "\n",
    "In order to speed up the calculation it's better to vectorize the data only once and then compare the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = [KNeighborsClassifier(),\n",
    "          LogisticRegression(),\n",
    "          DecisionTreeClassifier(),\n",
    "          SVC(),\n",
    "          RandomForestClassifier(),\n",
    "          ExtraTreesClassifier()]\n",
    "\n",
    "tvec = TfidfVectorizer(stop_words='english',\n",
    "                       sublinear_tf=True,\n",
    "                       max_df=0.5,\n",
    "                       max_features=1000)\n",
    "\n",
    "tvec.fit(data_train['data'])\n",
    "X_train = tvec.transform(data_train['data'])\n",
    "X_test = tvec.transform(data_test['data'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "0.277900960828\n",
      "                    p_alt.atheism  p_comp.graphics  p_sci.space  \\\n",
      "alt.atheism                   149               82           36   \n",
      "comp.graphics                 172              109           46   \n",
      "sci.space                     130              107           71   \n",
      "talk.religion.misc            105               63           36   \n",
      "\n",
      "                    p_talk.religion.misc  \n",
      "alt.atheism                           52  \n",
      "comp.graphics                         62  \n",
      "sci.space                             86  \n",
      "talk.religion.misc                    47  \n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.728011825573\n",
      "                    p_alt.atheism  p_comp.graphics  p_sci.space  \\\n",
      "alt.atheism                   187               16           60   \n",
      "comp.graphics                   8              340           39   \n",
      "sci.space                      23               23          338   \n",
      "talk.religion.misc             78               16           37   \n",
      "\n",
      "                    p_talk.religion.misc  \n",
      "alt.atheism                           56  \n",
      "comp.graphics                          2  \n",
      "sci.space                             10  \n",
      "talk.religion.misc                   120  \n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "0.60310421286\n",
      "                    p_alt.atheism  p_comp.graphics  p_sci.space  \\\n",
      "alt.atheism                   134               24           47   \n",
      "comp.graphics                  23              298           38   \n",
      "sci.space                      47               33          253   \n",
      "talk.religion.misc             87               13           20   \n",
      "\n",
      "                    p_talk.religion.misc  \n",
      "alt.atheism                          114  \n",
      "comp.graphics                         30  \n",
      "sci.space                             61  \n",
      "talk.religion.misc                   131  \n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.291204730229\n",
      "                    p_alt.atheism  p_comp.graphics  p_sci.space  \\\n",
      "alt.atheism                     0                0          319   \n",
      "comp.graphics                   0                0          389   \n",
      "sci.space                       0                0          394   \n",
      "talk.religion.misc              0                0          251   \n",
      "\n",
      "                    p_talk.religion.misc  \n",
      "alt.atheism                            0  \n",
      "comp.graphics                          0  \n",
      "sci.space                              0  \n",
      "talk.religion.misc                     0  \n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "0.667405764967\n",
      "                    p_alt.atheism  p_comp.graphics  p_sci.space  \\\n",
      "alt.atheism                   193               18           43   \n",
      "comp.graphics                  20              324           33   \n",
      "sci.space                      53               23          284   \n",
      "talk.religion.misc            105               21           23   \n",
      "\n",
      "                    p_talk.religion.misc  \n",
      "alt.atheism                           65  \n",
      "comp.graphics                         12  \n",
      "sci.space                             34  \n",
      "talk.religion.misc                   102  \n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "0.667405764967\n",
      "                    p_alt.atheism  p_comp.graphics  p_sci.space  \\\n",
      "alt.atheism                   182               23           37   \n",
      "comp.graphics                  15              330           27   \n",
      "sci.space                      38               37          287   \n",
      "talk.religion.misc            106               20           21   \n",
      "\n",
      "                    p_talk.religion.misc  \n",
      "alt.atheism                           77  \n",
      "comp.graphics                         17  \n",
      "sci.space                             32  \n",
      "talk.religion.misc                   104  \n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "\n",
    "for model in models:\n",
    "    print model\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    print score\n",
    "    cm = docm(y_test, y_pred, names)\n",
    "    print cm\n",
    "    res.append([model, score])\n",
    "\n",
    "# pd.DataFrame(res, columns=['model', 'score']).to_csv('../../../5.2-lesson/assets/datasets/20newsgroups/model_comparison.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Other classifiers\n",
    "\n",
    "Adapt the code from [this example](http://scikit-learn.org/stable/auto_examples/text/document_classification_20newsgroups.html#example-text-document-classification-20newsgroups-py) to compare across all the classifiers suggested and to display the final plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Ridge Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, random_state=None, solver='lsqr',\n",
      "        tol=0.01)\n",
      "train time: 0.030s\n",
      "test time:  0.000s\n",
      "accuracy:   0.708\n",
      "dimensionality: 1000\n",
      "density: 1.000000\n",
      "top 10 keywords per class:\n",
      "alt.atheism: worse makes satan atheist religion punishment islamic atheists a...\n",
      "talk.religion.misc: video using images points image hi file 3d computer graphics\n",
      "comp.graphics: 23 star launch sci engineering flight spacecraft orbit nasa space\n",
      "sci.space: authority kent context christ sin children order christian christi...\n",
      "()\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.61      0.53      0.56       319\n",
      "talk.religion.misc       0.85      0.85      0.85       389\n",
      "     comp.graphics       0.72      0.82      0.77       394\n",
      "         sci.space       0.57      0.53      0.55       251\n",
      "\n",
      "       avg / total       0.70      0.71      0.70      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[168  15  58  78]\n",
      " [ 14 332  37   6]\n",
      " [ 26  25 324  19]\n",
      " [ 68  20  29 134]]\n",
      "()\n",
      "================================================================================\n",
      "Perceptron\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
      "      n_iter=50, n_jobs=1, penalty=None, random_state=0, shuffle=True,\n",
      "      verbose=0, warm_start=False)\n",
      "train time: 0.034s\n",
      "test time:  0.000s\n",
      "accuracy:   0.668\n",
      "dimensionality: 1000\n",
      "density: 0.977750\n",
      "top 10 keywords per class:\n",
      "alt.atheism: description islamic nation materials atheists charge atheist ath...\n",
      "talk.religion.misc: image screen 50 half video points article 3d file graphics\n",
      "comp.graphics: like nasa flight shuttle launch expected spacecraft orbit dc s...\n",
      "sci.space: clearly elements dead children christ order authority holy taken sin\n",
      "()\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.52      0.58      0.55       319\n",
      "talk.religion.misc       0.86      0.79      0.83       389\n",
      "     comp.graphics       0.75      0.72      0.74       394\n",
      "         sci.space       0.48      0.51      0.50       251\n",
      "\n",
      "       avg / total       0.68      0.67      0.67      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[185   8  38  88]\n",
      " [ 22 308  38  21]\n",
      " [ 54  28 283  29]\n",
      " [ 94  13  16 128]]\n",
      "()\n",
      "================================================================================\n",
      "Passive-Aggressive\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "PassiveAggressiveClassifier(C=1.0, class_weight=None, fit_intercept=True,\n",
      "              loss='hinge', n_iter=50, n_jobs=1, random_state=None,\n",
      "              shuffle=True, verbose=0, warm_start=False)\n",
      "train time: 0.045s\n",
      "test time:  0.000s\n",
      "accuracy:   0.676\n",
      "dimensionality: 1000\n",
      "density: 0.997500\n",
      "top 10 keywords per class:\n",
      "alt.atheism: fit valid makes wish attempt atheism atheists islamic atheist bobby\n",
      "talk.religion.misc: 50 number points half article file image 3d original grap...\n",
      "comp.graphics: shuttle expected rocket mars launch nasa spacecraft dc orbit s...\n",
      "sci.space: dead reply authority generally christ taken 100 holy order sin\n",
      "()\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.56      0.55      0.56       319\n",
      "talk.religion.misc       0.86      0.80      0.83       389\n",
      "     comp.graphics       0.71      0.78      0.74       394\n",
      "         sci.space       0.49      0.47      0.48       251\n",
      "\n",
      "       avg / total       0.68      0.68      0.68      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[176   7  53  83]\n",
      " [ 16 312  46  15]\n",
      " [ 30  30 308  26]\n",
      " [ 91  15  26 119]]\n",
      "()\n",
      "================================================================================\n",
      "kNN\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michael/anaconda/lib/python2.7/site-packages/sklearn/linear_model/ridge.py:299: UserWarning: In Ridge, only 'sag' solver can currently fit the intercept when X is sparse. Solver has been automatically changed into 'sag'.\n",
      "  warnings.warn(\"In Ridge, only 'sag' solver can currently fit the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.003s\n",
      "test time:  0.114s\n",
      "accuracy:   0.248\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.24      0.37      0.29       319\n",
      "talk.religion.misc       0.31      0.28      0.29       389\n",
      "     comp.graphics       0.31      0.12      0.18       394\n",
      "         sci.space       0.18      0.25      0.21       251\n",
      "\n",
      "       avg / total       0.27      0.25      0.24      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[117  73  44  85]\n",
      " [160 107  38  84]\n",
      " [118 103  48 125]\n",
      " [102  61  24  64]]\n",
      "()\n",
      "================================================================================\n",
      "Random forest\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "train time: 1.297s\n",
      "test time:  0.049s\n",
      "accuracy:   0.700\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.58      0.61      0.59       319\n",
      "talk.religion.misc       0.82      0.87      0.85       389\n",
      "     comp.graphics       0.77      0.75      0.76       394\n",
      "         sci.space       0.52      0.47      0.49       251\n",
      "\n",
      "       avg / total       0.70      0.70      0.70      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[194  22  40  63]\n",
      " [ 17 339  25   8]\n",
      " [ 32  30 297  35]\n",
      " [ 92  20  22 117]]\n",
      "()\n",
      "================================================================================\n",
      "L2 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='l2', max_iter=1000, multi_class='ovr',\n",
      "     penalty='l2', random_state=None, tol=0.001, verbose=0)\n",
      "train time: 0.021s\n",
      "test time:  0.000s\n",
      "accuracy:   0.703\n",
      "dimensionality: 1000\n",
      "density: 1.000000\n",
      "top 10 keywords per class:\n",
      "alt.atheism: punishment satan worse eternal atheist makes islamic atheists bo...\n",
      "talk.religion.misc: half video card points hi file image 3d computer graphics\n",
      "comp.graphics: solar mars flight launch dc shuttle spacecraft nasa orbit space\n",
      "sci.space: holy taken authority children sin fbi christ christians christian ...\n",
      "()\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.59      0.54      0.56       319\n",
      "talk.religion.misc       0.86      0.85      0.86       389\n",
      "     comp.graphics       0.73      0.81      0.77       394\n",
      "         sci.space       0.54      0.51      0.52       251\n",
      "\n",
      "       avg / total       0.70      0.70      0.70      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[172  13  51  83]\n",
      " [ 14 331  35   9]\n",
      " [ 28  27 320  19]\n",
      " [ 80  13  30 128]]\n",
      "()\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 0.034s\n",
      "test time:  0.000s\n",
      "accuracy:   0.680\n",
      "dimensionality: 1000\n",
      "density: 0.993250\n",
      "top 10 keywords per class:\n",
      "alt.atheism: million atheist makes natural tells eternal atheists islamic bob...\n",
      "talk.religion.misc: interested interactive card hi half image 3d file compute...\n",
      "comp.graphics: shuttle rocket engineering flight mars dc nasa spacecraft orbi...\n",
      "sci.space: black authority kent fbi christian christians christ taken sin order\n",
      "()\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.59      0.51      0.55       319\n",
      "talk.religion.misc       0.84      0.84      0.84       389\n",
      "     comp.graphics       0.75      0.74      0.75       394\n",
      "         sci.space       0.46      0.56      0.51       251\n",
      "\n",
      "       avg / total       0.69      0.68      0.68      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[163  16  40 100]\n",
      " [ 13 325  33  18]\n",
      " [ 26  31 291  46]\n",
      " [ 73  15  22 141]]\n",
      "()\n",
      "================================================================================\n",
      "L1 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='l2', max_iter=1000, multi_class='ovr',\n",
      "     penalty='l1', random_state=None, tol=0.001, verbose=0)\n",
      "train time: 0.065s\n",
      "test time:  0.000s\n",
      "accuracy:   0.704\n",
      "dimensionality: 1000\n",
      "density: 0.396750\n",
      "top 10 keywords per class:\n",
      "alt.atheism: stay punishment tells worse satan atheist atheists islamic athei...\n",
      "talk.religion.misc: sgi video computer hi points file image card 3d graphics\n",
      "comp.graphics: mars 23 launch dc shuttle flight nasa spacecraft orbit space\n",
      "sci.space: actions holy christians christian sin order children authority fbi...\n",
      "()\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.59      0.54      0.56       319\n",
      "talk.religion.misc       0.88      0.84      0.86       389\n",
      "     comp.graphics       0.73      0.81      0.77       394\n",
      "         sci.space       0.54      0.54      0.54       251\n",
      "\n",
      "       avg / total       0.70      0.70      0.70      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[173  11  51  84]\n",
      " [ 14 325  40  10]\n",
      " [ 29  22 320  23]\n",
      " [ 79  11  26 135]]\n",
      "()\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='l1', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michael/anaconda/lib/python2.7/site-packages/sklearn/svm/classes.py:197: DeprecationWarning: loss='l2' has been deprecated in favor of loss='squared_hinge' as of 0.16. Backward compatibility for the loss='l2' will be removed in 1.0\n",
      "  DeprecationWarning)\n",
      "/Users/michael/anaconda/lib/python2.7/site-packages/sklearn/svm/classes.py:197: DeprecationWarning: loss='l2' has been deprecated in favor of loss='squared_hinge' as of 0.16. Backward compatibility for the loss='l2' will be removed in 1.0\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.189s\n",
      "test time:  0.001s\n",
      "accuracy:   0.680\n",
      "dimensionality: 1000\n",
      "density: 0.521750\n",
      "top 10 keywords per class:\n",
      "alt.atheism: worse valid makes islamic nation atheist tells atheism atheists ...\n",
      "talk.religion.misc: hi card computer file 24 image 3d animation points graphics\n",
      "comp.graphics: astro satellite flight launch shuttle spacecraft dc rocket orb...\n",
      "sci.space: fbi holy children taken reply sin elements christ authority order\n",
      "()\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.58      0.53      0.55       319\n",
      "talk.religion.misc       0.77      0.83      0.80       389\n",
      "     comp.graphics       0.77      0.76      0.76       394\n",
      "         sci.space       0.51      0.51      0.51       251\n",
      "\n",
      "       avg / total       0.68      0.68      0.68      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[170  27  35  87]\n",
      " [ 18 323  35  13]\n",
      " [ 26  46 300  22]\n",
      " [ 81  22  21 127]]\n",
      "()\n",
      "================================================================================\n",
      "Elastic-Net penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 0.164s\n",
      "test time:  0.000s\n",
      "accuracy:   0.679\n",
      "dimensionality: 1000\n",
      "density: 0.872500\n",
      "top 10 keywords per class:\n",
      "alt.atheism: worse makes atheist natural tells eternal islamic atheists bobby...\n",
      "talk.religion.misc: points interactive card hi half image file 3d computer gr...\n",
      "comp.graphics: shuttle engineering flight rocket mars nasa dc spacecraft orbi...\n",
      "sci.space: black kent christian fbi authority christians christ taken sin order\n",
      "()\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.59      0.52      0.55       319\n",
      "talk.religion.misc       0.76      0.86      0.81       389\n",
      "     comp.graphics       0.76      0.74      0.75       394\n",
      "         sci.space       0.51      0.51      0.51       251\n",
      "\n",
      "       avg / total       0.67      0.68      0.68      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[167  28  38  86]\n",
      " [ 12 334  32  11]\n",
      " [ 27  51 291  25]\n",
      " [ 78  25  21 127]]\n",
      "()\n",
      "================================================================================\n",
      "NearestCentroid (aka Rocchio classifier)\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "NearestCentroid(metric='euclidean', shrink_threshold=None)\n",
      "train time: 0.005s\n",
      "test time:  0.001s\n",
      "accuracy:   0.715\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.58      0.55      0.56       319\n",
      "talk.religion.misc       0.88      0.83      0.85       389\n",
      "     comp.graphics       0.75      0.82      0.78       394\n",
      "         sci.space       0.58      0.59      0.58       251\n",
      "\n",
      "       avg / total       0.72      0.72      0.71      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[174  16  46  83]\n",
      " [ 21 323  40   5]\n",
      " [ 34  18 324  18]\n",
      " [ 71  11  22 147]]\n",
      "()\n",
      "================================================================================\n",
      "Naive Bayes\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "train time: 0.003s\n",
      "test time:  0.001s\n",
      "accuracy:   0.738\n",
      "dimensionality: 1000\n",
      "density: 1.000000\n",
      "top 10 keywords per class:\n",
      "alt.atheism: said know religion does say just think people don god\n",
      "talk.religion.misc: hi looking does program image know files file thanks grap...\n",
      "comp.graphics: don earth moon think launch orbit just like nasa space\n",
      "sci.space: bible know think christians just don christian people jesus god\n",
      "()\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.60      0.59      0.60       319\n",
      "talk.religion.misc       0.88      0.88      0.88       389\n",
      "     comp.graphics       0.75      0.86      0.80       394\n",
      "         sci.space       0.64      0.51      0.57       251\n",
      "\n",
      "       avg / total       0.73      0.74      0.73      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[188  15  50  66]\n",
      " [ 11 343  34   1]\n",
      " [ 26  24 338   6]\n",
      " [ 86   8  28 129]]\n",
      "()\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "train time: 0.005s\n",
      "test time:  0.001s\n",
      "accuracy:   0.670\n",
      "dimensionality: 1000\n",
      "density: 1.000000\n",
      "top 10 keywords per class:\n",
      "alt.atheism: time does know god like say just think people don\n",
      "talk.religion.misc: just don program need does use like know graphics thanks\n",
      "comp.graphics: earth use time think know nasa don just like space\n",
      "sci.space: say way like does know think god don just people\n",
      "()\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.59      0.65      0.62       319\n",
      "talk.religion.misc       0.63      0.90      0.74       389\n",
      "     comp.graphics       0.85      0.64      0.73       394\n",
      "         sci.space       0.64      0.37      0.47       251\n",
      "\n",
      "       avg / total       0.69      0.67      0.66      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[207  54  12  46]\n",
      " [ 11 352  25   1]\n",
      " [ 26 109 253   6]\n",
      " [106  44   7  94]]\n",
      "()\n",
      "================================================================================\n",
      "LinearSVC with L1-based feature selection\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Pipeline(steps=[('feature_selection', LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "     verbose=0)), ('classification', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))])\n",
      "train time: 0.102s\n",
      "test time:  0.002s\n",
      "accuracy:   0.710\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.60      0.54      0.57       319\n",
      "talk.religion.misc       0.87      0.85      0.86       389\n",
      "     comp.graphics       0.73      0.83      0.78       394\n",
      "         sci.space       0.55      0.53      0.54       251\n",
      "\n",
      "       avg / total       0.71      0.71      0.71      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[173  13  53  80]\n",
      " [ 13 329  38   9]\n",
      " [ 26  23 326  19]\n",
      " [ 74  15  29 133]]\n",
      "()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michael/anaconda/lib/python2.7/site-packages/sklearn/utils/__init__.py:93: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/michael/anaconda/lib/python2.7/site-packages/sklearn/utils/__init__.py:93: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvAAAAIxCAYAAAArEoxrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndYgJvCRJktQhJvCSJElSh/x/BpsYqqQSS3AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116b6a7d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "\n",
    "feature_names = np.array(tvec.get_feature_names())\n",
    "\n",
    "def trim(s):\n",
    "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
    "    return s if len(s) <= 80 else s[:77] + \"...\"\n",
    "\n",
    "###############################################################################\n",
    "# Benchmark classifiers\n",
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "\n",
    "        if feature_names is not None:\n",
    "            print(\"top 10 keywords per class:\")\n",
    "            for i, category in enumerate(categories):\n",
    "                top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "                print(trim(\"%s: %s\"\n",
    "                      % (category, \" \".join(feature_names[top10]))))\n",
    "        print()\n",
    "\n",
    "\n",
    "    print(\"classification report:\")\n",
    "    print(metrics.classification_report(y_test, pred,\n",
    "                                        target_names=categories))\n",
    "\n",
    "\n",
    "    print(\"confusion matrix:\")\n",
    "    print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    return clf_descr, score, train_time, test_time\n",
    "\n",
    "\n",
    "results = []\n",
    "for clf, name in (\n",
    "        (RidgeClassifier(tol=1e-2, solver=\"lsqr\"), \"Ridge Classifier\"),\n",
    "        (Perceptron(n_iter=50), \"Perceptron\"),\n",
    "        (PassiveAggressiveClassifier(n_iter=50), \"Passive-Aggressive\"),\n",
    "        (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
    "        (RandomForestClassifier(n_estimators=100), \"Random forest\")):\n",
    "    print('=' * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf))\n",
    "\n",
    "for penalty in [\"l2\", \"l1\"]:\n",
    "    print('=' * 80)\n",
    "    print(\"%s penalty\" % penalty.upper())\n",
    "    # Train Liblinear model\n",
    "    results.append(benchmark(LinearSVC(loss='l2', penalty=penalty,\n",
    "                                            dual=False, tol=1e-3)))\n",
    "\n",
    "    # Train SGD model\n",
    "    results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "                                           penalty=penalty)))\n",
    "\n",
    "# Train SGD with Elastic Net penalty\n",
    "print('=' * 80)\n",
    "print(\"Elastic-Net penalty\")\n",
    "results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "                                       penalty=\"elasticnet\")))\n",
    "\n",
    "# Train NearestCentroid without threshold\n",
    "print('=' * 80)\n",
    "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
    "results.append(benchmark(NearestCentroid()))\n",
    "\n",
    "# Train sparse Naive Bayes classifiers\n",
    "print('=' * 80)\n",
    "print(\"Naive Bayes\")\n",
    "results.append(benchmark(MultinomialNB(alpha=.01)))\n",
    "results.append(benchmark(BernoulliNB(alpha=.01)))\n",
    "\n",
    "print('=' * 80)\n",
    "print(\"LinearSVC with L1-based feature selection\")\n",
    "# The smaller C, the stronger the regularization.\n",
    "# The more regularization, the more sparsity.\n",
    "results.append(benchmark(Pipeline([\n",
    "  ('feature_selection', LinearSVC(penalty=\"l1\", dual=False, tol=1e-3)),\n",
    "  ('classification', LinearSVC())\n",
    "])))\n",
    "\n",
    "# make some plots\n",
    "\n",
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "clf_names, score, training_time, test_time = results\n",
    "training_time = np.array(training_time) / np.max(training_time)\n",
    "test_time = np.array(test_time) / np.max(test_time)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Score\")\n",
    "plt.barh(indices, score, .2, label=\"score\", color='r')\n",
    "plt.barh(indices + .3, training_time, .2, label=\"training time\", color='g')\n",
    "plt.barh(indices + .6, test_time, .2, label=\"test time\", color='b')\n",
    "plt.yticks(())\n",
    "plt.legend(loc='best')\n",
    "plt.subplots_adjust(left=.25)\n",
    "plt.subplots_adjust(top=.95)\n",
    "plt.subplots_adjust(bottom=.05)\n",
    "\n",
    "for i, c in zip(indices, clf_names):\n",
    "    plt.text(-.3, i, c)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Bonus: NLTK\n",
    "\n",
    "NLTK is a vast library. Can you find some interesting bits to share with classmates?\n",
    "Start here: http://www.nltk.org/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
