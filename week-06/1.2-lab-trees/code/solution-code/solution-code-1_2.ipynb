{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees Lab\n",
    "\n",
    "In this lab we will discover how to apply decision trees to regression and classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# read in vehicle data\n",
    "vehicles = pd.read_csv('../../assets/datasets/used_cars.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: Build a classification tree\n",
    "\n",
    "How do you build a decision tree? You're going to find out by building one in pairs!\n",
    "\n",
    "Your training data is a tiny dataset of [used vehicle sale prices](../../assets/datasets/used_cars.csv). Your goal is to predict the price of a car. Here are your instructions:\n",
    "\n",
    "1. Read the data into Pandas.\n",
    "- Explore the data by sorting, plotting, or split-apply-combine (aka `group_by`).\n",
    "- Get the median value of 'price.' Create a binary column that indicates if the price is above or below the median. \n",
    "- Decide which feature is the most important predictor, and use that to make your first split. (Only binary splits are allowed!)\n",
    "- After making your first split, you should actually split your data in Pandas into two parts, and then explore each part to figure out what other splits to make.\n",
    "- Decide if you need additional splits along other features\n",
    "- Stop making splits once you are convinced that it strikes a good balance between underfitting and overfitting. (As always, your goal is to build a model that generalizes well!)\n",
    "- You are allowed to split on the same variable multiple times!\n",
    "- Draw your tree on your desk, making sure to label your leaves with the car/truck prediction for the observations in that \"bucket\".\n",
    "- When you're finished, review your tree to make sure nothing is backwards. (Remember: follow the left branch if the rule is true, and follow the right branch if the rule is false.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>miles</th>\n",
       "      <th>doors</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22000</td>\n",
       "      <td>2012</td>\n",
       "      <td>13000</td>\n",
       "      <td>2</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14000</td>\n",
       "      <td>2010</td>\n",
       "      <td>30000</td>\n",
       "      <td>2</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13000</td>\n",
       "      <td>2010</td>\n",
       "      <td>73500</td>\n",
       "      <td>4</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9500</td>\n",
       "      <td>2009</td>\n",
       "      <td>78000</td>\n",
       "      <td>4</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9000</td>\n",
       "      <td>2007</td>\n",
       "      <td>47000</td>\n",
       "      <td>4</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4000</td>\n",
       "      <td>2006</td>\n",
       "      <td>124000</td>\n",
       "      <td>2</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3000</td>\n",
       "      <td>2004</td>\n",
       "      <td>177000</td>\n",
       "      <td>4</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2000</td>\n",
       "      <td>2004</td>\n",
       "      <td>209000</td>\n",
       "      <td>4</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3000</td>\n",
       "      <td>2003</td>\n",
       "      <td>138000</td>\n",
       "      <td>2</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1900</td>\n",
       "      <td>2003</td>\n",
       "      <td>160000</td>\n",
       "      <td>4</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2500</td>\n",
       "      <td>2003</td>\n",
       "      <td>190000</td>\n",
       "      <td>2</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5000</td>\n",
       "      <td>2001</td>\n",
       "      <td>62000</td>\n",
       "      <td>4</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1800</td>\n",
       "      <td>1999</td>\n",
       "      <td>163000</td>\n",
       "      <td>2</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1300</td>\n",
       "      <td>1997</td>\n",
       "      <td>138000</td>\n",
       "      <td>4</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    price  year   miles  doors   type\n",
       "0   22000  2012   13000      2    car\n",
       "1   14000  2010   30000      2    car\n",
       "2   13000  2010   73500      4    car\n",
       "3    9500  2009   78000      4    car\n",
       "4    9000  2007   47000      4    car\n",
       "5    4000  2006  124000      2    car\n",
       "6    3000  2004  177000      4    car\n",
       "7    2000  2004  209000      4  truck\n",
       "8    3000  2003  138000      2    car\n",
       "9    1900  2003  160000      4    car\n",
       "10   2500  2003  190000      2  truck\n",
       "11   5000  2001   62000      4    car\n",
       "12   1800  1999  163000      2  truck\n",
       "13   1300  1997  138000      4    car"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vehicles['type'] = vehicles.type.map({'car':0, 'truck':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>miles</th>\n",
       "      <th>doors</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22000</td>\n",
       "      <td>2012</td>\n",
       "      <td>13000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price  year  miles  doors  type\n",
       "0  22000  2012  13000      2     0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicles.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "median = np.median(vehicles.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3500.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vehicles['price_binary'] = vehicles['price'].apply(lambda x: 1 if x > median else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "over_124k = vehicles[vehicles.miles > 124000]\n",
    "under_124k = vehicles[vehicles.miles <= 124000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>miles</th>\n",
       "      <th>doors</th>\n",
       "      <th>type</th>\n",
       "      <th>price_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3000</td>\n",
       "      <td>2004</td>\n",
       "      <td>177000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2000</td>\n",
       "      <td>2004</td>\n",
       "      <td>209000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3000</td>\n",
       "      <td>2003</td>\n",
       "      <td>138000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1900</td>\n",
       "      <td>2003</td>\n",
       "      <td>160000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2500</td>\n",
       "      <td>2003</td>\n",
       "      <td>190000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1800</td>\n",
       "      <td>1999</td>\n",
       "      <td>163000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1300</td>\n",
       "      <td>1997</td>\n",
       "      <td>138000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    price  year   miles  doors  type  price_binary\n",
       "6    3000  2004  177000      4     0             0\n",
       "7    2000  2004  209000      4     1             0\n",
       "8    3000  2003  138000      2     0             0\n",
       "9    1900  2003  160000      4     0             0\n",
       "10   2500  2003  190000      2     1             0\n",
       "12   1800  1999  163000      2     1             0\n",
       "13   1300  1997  138000      4     0             0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "over_124k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>miles</th>\n",
       "      <th>doors</th>\n",
       "      <th>type</th>\n",
       "      <th>price_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22000</td>\n",
       "      <td>2012</td>\n",
       "      <td>13000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14000</td>\n",
       "      <td>2010</td>\n",
       "      <td>30000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13000</td>\n",
       "      <td>2010</td>\n",
       "      <td>73500</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9500</td>\n",
       "      <td>2009</td>\n",
       "      <td>78000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9000</td>\n",
       "      <td>2007</td>\n",
       "      <td>47000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4000</td>\n",
       "      <td>2006</td>\n",
       "      <td>124000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5000</td>\n",
       "      <td>2001</td>\n",
       "      <td>62000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    price  year   miles  doors  type  price_binary\n",
       "0   22000  2012   13000      2     0             1\n",
       "1   14000  2010   30000      2     0             1\n",
       "2   13000  2010   73500      4     0             1\n",
       "3    9500  2009   78000      4     0             1\n",
       "4    9000  2007   47000      4     0             1\n",
       "5    4000  2006  124000      2     0             1\n",
       "11   5000  2001   62000      4     0             1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "under_124k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How does a computer build a decision tree?\n",
    "\n",
    "The ideal approach would be for the computer to consider every possible partition of the feature space. However, this is computationally infeasible, so instead an approach is used called **recursive binary splitting:**\n",
    "\n",
    "- Begin at the top of the tree.\n",
    "- For every single predictor, examine every possible cutpoint, and choose the predictor and cutpoint such that the resulting tree has the **highest purity**. Make that split.\n",
    "- Repeat the examination for the two resulting regions, and again make a single split (in one of the regions) to minimize the MSE.\n",
    "- Keep repeating this process until a stopping criteria is met.\n",
    "\n",
    "**How does it know when to stop?**\n",
    "\n",
    "1. We could define a stopping criterion, such as a **maximum depth** of the tree or the **minimum number of samples in the leaf**.\n",
    "2. We could grow the tree deep, and then \"prune\" it back using a method such as \"cost complexity pruning\" (aka \"weakest link pruning\").\n",
    "\n",
    "Method 2 involves setting a tuning parameter that penalizes the tree for having too many leaves. As the parameter is increased, branches automatically get pruned from the tree, resulting in smaller and smaller trees. The tuning parameter can be selected through cross-validation.\n",
    "\n",
    "Note: **Method 2 is not currently supported by scikit-learn**, and so we will use Method 1 instead.\n",
    "\n",
    "Note that classification trees easily handle **more than two response classes**! (How have other classification models we've seen handled this scenario?)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Build a classification tree in scikit-learn\n",
    "\n",
    "Building a tree by hand was not so easy, and also not ideal. Let's use scikit-learn to build an optimal regression tree. Do the following:\n",
    "\n",
    "- Check for missing values\n",
    "- Map the `type` column to a binary variable\n",
    "- Create a matrix `X` that contains the feature values and a vector `y` that contains the price values as a binary (above/below median)\n",
    "- Split the data into train-test using a random state of 42 and test_size of 30%\n",
    "- Import and initialize the `DecisionTreeClassifier` class from scikit-learn\n",
    "- Fit it to the training set\n",
    "- Predict the values of the test set\n",
    "- Display the predicted and actual values in a confusion matrix\n",
    "- Use score report to judge the goodness of the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = vehicles.drop('price', axis = 1).drop('price_binary', axis =1)\n",
    "y = vehicles['price_binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>miles</th>\n",
       "      <th>doors</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012</td>\n",
       "      <td>13000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>30000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>73500</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>78000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007</td>\n",
       "      <td>47000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  miles  doors  type\n",
       "0  2012  13000      2     0\n",
       "1  2010  30000      2     0\n",
       "2  2010  73500      4     0\n",
       "3  2009  78000      4     0\n",
       "4  2007  47000      4     0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=1, splitter='best')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After you've cleaned and split the data, run this model:\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "treeclass = DecisionTreeClassifier(random_state=1)\n",
    "treeclass.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### And a function to plot your confusion matrix:\n",
    "import matplotlib.patheffects as path_effects\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', labels=['Positive','Negative'], cmap=plt.cm.Blues):\n",
    "    \n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    \n",
    "    tick_marks = np.arange(2)\n",
    "    plt.xticks(tick_marks, labels)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "        \n",
    "    plt.title(title)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    width, height = cm.shape\n",
    "    \n",
    "    for x in xrange(width):\n",
    "        for y in xrange(height):\n",
    "            plt.annotate(str(cm[x][y]), xy=(y, x), \n",
    "                        horizontalalignment='center',\n",
    "                        verticalalignment='center',\n",
    "                        color = 'white',\n",
    "                        fontsize=18).set_path_effects([path_effects.Stroke(linewidth=1, foreground='black'),\n",
    "                                                       path_effects.Normal()]) #The last line here adds a text outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = treeclass.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9     0\n",
       "11    1\n",
       "0     1\n",
       "12    0\n",
       "5     1\n",
       "Name: price_binary, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0],\n",
       "       [1, 2]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, preds)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfEAAAHdCAYAAAANXEAwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116b409d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfEAAAHdCAYAAAANXEAwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuCRJhTLEJUkq1P8H/yeYxN7OTc8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116b40350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#do the same thing on the full dataset, even though we trained on part of it.\n",
    "#just for visualization's sake\n",
    "cm = confusion_matrix(y, treeclass.predict(X))\n",
    "plot_confusion_matrix(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.b Global parameters\n",
    "\n",
    "The `DecisionTreeClassifier` offers few global parameters that can be changed at initialization. For example one can set the `max_depth` or the `min_samples_leaf` parameters and impose global constraints on the space of solutions.\n",
    "\n",
    "1. Use `cross_val_score` with 3-fold cross validation to find the optimal value for the `max_depth` (explore values 1 - 10). Always set `random_state=1`\n",
    "- Plot the error as a function of `max_depth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>miles</th>\n",
       "      <th>doors</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012</td>\n",
       "      <td>13000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>30000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>73500</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>78000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007</td>\n",
       "      <td>47000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  miles  doors  type\n",
       "0  2012  13000      2     0\n",
       "1  2010  30000      2     0\n",
       "2  2010  73500      4     0\n",
       "3  2009  78000      4     0\n",
       "4  2007  47000      4     0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Use GridSearchCV to find the best Tree\n",
    "\n",
    "How do we know by pruning with max depth is the best model for us? Trees offer a variety of ways to pre-prune (that is, we tell a computer how to design the resulting tree with certain \"gotchas\").\n",
    "\n",
    "Measure           | What it does\n",
    "------------------|-------------\n",
    "max_depth         | How many nodes deep can the decision tree go?\n",
    "max_features      | Is there a cut off to the number of features to use?\n",
    "max_leaf_nodes    | How many leaves can be generated per node?\n",
    "min_samples_leaf  | How many samples need to be included at a leaf, at a minimum?  \n",
    "min_samples_split | How many samples need to be included at a node, at a minimum?\n",
    "\n",
    "1. Initialize reasonable ranges for all parameters and find the optimal combination using Grid Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PARAMETERS = {'max_depth':[1,2,3,4,5,6], 'max_features':[1,2,3,4], \n",
    "              'max_leaf_nodes':[5,6,7,8,9,10], 'min_samples_leaf':[1,2,3,4],\n",
    "              'min_samples_split':[1,2,3,4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2304 candidates, totalling 6912 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1258 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 6358 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=-1)]: Done 6912 out of 6912 | elapsed:   18.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_features': [1, 2, 3, 4], 'max_leaf_nodes': [5, 6, 7, 8, 9, 10], 'min_samples_split': [1, 2, 3, 4], 'max_depth': [1, 2, 3, 4, 5, 6], 'min_samples_leaf': [1, 2, 3, 4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "clf = GridSearchCV(model, PARAMETERS, verbose=True, n_jobs = -1)\n",
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: \n",
      " \n",
      " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=1, max_leaf_nodes=10, min_samples_leaf=1,\n",
      "            min_samples_split=4, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "print \"Best model: \\n \\n {}\".format(clf.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.c Feature importances\n",
    "\n",
    "The decision tree class exposes an attribute called `feature_importances_`.\n",
    "\n",
    "1. Check the importance of each feature. what's the most important feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  0.,  0.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeclass.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>miles</th>\n",
       "      <th>doors</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012</td>\n",
       "      <td>13000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>30000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>73500</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>78000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007</td>\n",
       "      <td>47000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  miles  doors  type\n",
       "0  2012  13000      2     0\n",
       "1  2010  30000      2     0\n",
       "2  2010  73500      4     0\n",
       "3  2009  78000      4     0\n",
       "4  2007  47000      4     0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.d Tree visualization\n",
    "\n",
    "Follow the example in the [documentation](http://scikit-learn.org/stable/modules/tree.html) to visualize the tree.\n",
    "You may have to install `pydotplus` and/or `graphviz` if you don't have them already.\n",
    "\n",
    "Note: `pydot` and `pydotplus` are interchangeable. `pydotplus` tends to have fewer errors, so use that if `pydot` isn't working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "InvocationException",
     "evalue": "GraphViz's executables not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvocationException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-80386583501c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                 special_characters=True)  \n\u001b[1;32m     11\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/michael/anaconda/lib/python2.7/site-packages/pydotplus/graphviz.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, prog)\u001b[0m\n\u001b[1;32m   1795\u001b[0m             self.__setattr__(\n\u001b[1;32m   1796\u001b[0m                 \u001b[0;34m'create_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfrmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1797\u001b[0;31m                 \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1798\u001b[0m             )\n\u001b[1;32m   1799\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'create_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfrmt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michael/anaconda/lib/python2.7/site-packages/pydotplus/graphviz.pyc\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, prog, format)\u001b[0m\n\u001b[1;32m   1958\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m                 raise InvocationException(\n\u001b[0;32m-> 1960\u001b[0;31m                     'GraphViz\\'s executables not found')\n\u001b[0m\u001b[1;32m   1961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1962\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprog\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvocationException\u001b[0m: GraphViz's executables not found"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO\n",
    "import pydotplus\n",
    "\n",
    "dot_data = StringIO()  \n",
    "export_graphviz(treeclass, out_file=dot_data,  \n",
    "                feature_names=X.columns,  \n",
    "                filled=True, rounded=True,  \n",
    "                special_characters=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "st = '/Users/michael/anaconda/lib/python2.7/site-packages/graphviz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/michael/anaconda/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append(st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting a tree diagram\n",
    "\n",
    "How do we read this decision tree?\n",
    "\n",
    "**Internal nodes:**\n",
    "\n",
    "- `samples` is the number of observations in that node before splitting\n",
    "- `mse` is the mean squared error calculated by comparing the actual response values in that node against the mean response value in that node\n",
    "- First line is the condition used to split that node (go left if true, go right if false)\n",
    "\n",
    "**Leaves:**\n",
    "\n",
    "- `gini` is a measure of purity\n",
    "- `samples` is the number of observations in that node\n",
    "- `value` is the mean response value in that node\n",
    "- [For regression: `mse` is the mean squared error calculated by comparing the actual response values in that node against \"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Regression trees\n",
    "\n",
    "Classification trees are very similar to regression trees. Here is a quick comparison:\n",
    "\n",
    "|regression trees|classification trees|\n",
    "|---|---|\n",
    "|predict a continuous response|predict a categorical response|\n",
    "|predict using mean response of each leaf|predict using most commonly occuring class of each leaf|\n",
    "|splits are chosen to minimize MSE|splits are chosen to minimize a different criterion (discussed below)|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How does a computer build a regression tree?\n",
    "Just like for a classification tree, it uses **recursive binary search**, but optimizes for lowest MSE instead of purity:\n",
    "\n",
    "- Begin at the top of the tree.\n",
    "- For every single predictor, examine every possible cutpoint, and choose the predictor and cutpoint such that the resulting tree has the **lowest possible mean squared error (MSE)**. Make that split.\n",
    "- Repeat the examination for the two resulting regions, and again make a single split (in one of the regions) to minimize the MSE.\n",
    "- Keep repeating this process until a stopping criteria is met."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a: Build a regression tree in scikit-learn\n",
    "\n",
    "Building a tree by hand was not so easy, and also not ideal. Let's use scikit-learn to build an optimal regression tree. Do the following:\n",
    "\n",
    "- Check for missing values\n",
    "- Map the `type` column to a binary variable\n",
    "- Create a matrix `X` that contains the feature values and a vector `y` that contains the price values\n",
    "- Split the data into train-test using a random state of 42 and test_size of 30%\n",
    "- Import and initialize the `DecisionTreeRegressor` class from scikit-learn with `max_depth=3` and `criterion = 'mse'`\n",
    "- Fit it to all the data\n",
    "- Use r2_score to judge the goodness of the regression\n",
    "- Release the constraint of `max_depth=3` and see if the regression improves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     22000\n",
       "1     14000\n",
       "2     13000\n",
       "3      9500\n",
       "4      9000\n",
       "5      4000\n",
       "6      3000\n",
       "7      2000\n",
       "8      3000\n",
       "9      1900\n",
       "10     2500\n",
       "11     5000\n",
       "12     1800\n",
       "13     1300\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = vehicles.price\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "treereg = DecisionTreeRegressor(random_state=1)\n",
    "treereg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = treereg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(preds)\n",
    "plt.plot(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'feature':X.columns, 'importance':treereg.feature_importances_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO\n",
    "import pydotplus\n",
    "dot_data = StringIO()  \n",
    "\n",
    "export_graphviz(treereg, out_file=dot_data,  \n",
    "                feature_names=X.columns,  \n",
    "                filled=True, rounded=True,  \n",
    "                special_characters=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PARAMETERS = {'max_depth':[1,2,3,4,5,6], 'max_features':[1,2,3,4], \n",
    "              'max_leaf_nodes':[5,6,7,8,9,10], 'min_samples_leaf':[1,2,3,4],\n",
    "              'min_samples_split':[1,2,3,4]}\n",
    "SCORING = 'mean_squared_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Grid Search\n",
    "model = DecisionTreeRegressor()\n",
    "clf = GridSearchCV(model, PARAMETERS, scoring=SCORING, verbose=True, n_jobs=-1)\n",
    "clf.fit(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#After completion, show the final best results and scores\n",
    "print \"Best model: \\n \\n {}\".format(clf.best_estimator_)\n",
    "print \n",
    "print \"Best score was {}\".format(clf.best_score_)\n",
    "print np.sqrt(-clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at what's happening behind grid search:\n",
    "\n",
    "1. Use `cross_val_score` with 3-fold cross validation to find the optimal value for the `max_depth` (explore values 1 - 10). Note that you will have to set `scoring='mean_squared_error'` as criterion for score. Always set `random_state=1`\n",
    "- Plot the error as a function of `max_depth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use cross-validation to find best max_depth\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "best_score = -1\n",
    "best_depth = 0\n",
    "for i in range(1, 9):\n",
    "    treereg = DecisionTreeRegressor(max_depth=i, random_state=1)\n",
    "    scores = cross_val_score(treereg, X, y, cv=3, scoring='mean_squared_error')\n",
    "    current_score = np.mean(np.sqrt(-scores))\n",
    "    # If the score mean is better than the current best, or best is the default (-1), then update!\n",
    "    if current_score < best_score or best_score == -1:\n",
    "        best_score = current_score\n",
    "        best_depth = i\n",
    "    # store to plot anyway!\n",
    "    all_scores.append(current_score)\n",
    "    \n",
    "print \"Best score: %s\" % best_score\n",
    "print \"Best depth: %s\" % best_depth\n",
    "\n",
    "# now actually fit the model\n",
    "treereg = DecisionTreeRegressor(max_depth=best_depth, random_state=1)\n",
    "treereg.fit(X, y)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(1, 9), all_scores)\n",
    "plt.xlabel('x=max tree depth')\n",
    "plt.ylabel('training error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
